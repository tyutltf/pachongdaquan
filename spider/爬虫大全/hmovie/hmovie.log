2019-06-15 14:18:30 [scrapy.utils.log] INFO: Scrapy 1.6.0 started (bot: hmovie)
2019-06-15 14:18:30 [scrapy.utils.log] INFO: Versions: lxml 4.3.4.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.5.1, w3lib 1.20.0, Twisted 18.4.0, Python 3.6.5 (v3.6.5:f59c0932b4, Mar 28 2018, 17:00:18) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 19.0.0 (OpenSSL 1.1.0i  14 Aug 2018), cryptography 2.3.1, Platform Windows-10-10.0.17763-SP0
2019-06-15 14:18:30 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'hmovie', 'LOG_FILE': 'hmovie.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'hmovie.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['hmovie.spiders']}
2019-06-15 14:18:30 [scrapy.extensions.telnet] INFO: Telnet Password: dd92b0433f30bec4
2019-06-15 14:18:30 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2019-06-15 14:18:32 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'hmovie.rotate_useragent.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'hmovie.middlewares.HmovieDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-06-15 14:18:32 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'hmovie.middlewares.HmovieSpiderMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-06-15 14:18:32 [scrapy.middleware] INFO: Enabled item pipelines:
['hmovie.pipelines.HmoviePipeline']
2019-06-15 14:18:32 [scrapy.core.engine] INFO: Spider opened
2019-06-15 14:18:32 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-06-15 14:18:32 [hmovieurl] INFO: Spider opened: hmovieurl
2019-06-15 14:18:32 [py.warnings] WARNING: C:\Users\ltf\AppData\Local\Programs\Python\Python36\lib\site-packages\scrapy\spidermiddlewares\offsite.py:61: URLWarning: allowed_domains accepts only domains, not URLs. Ignoring URL entry https://bx88222.com in allowed_domains.
  warnings.warn(message, URLWarning)

2019-06-15 14:18:32 [hmovieurl] INFO: Spider opened: hmovieurl
2019-06-15 14:18:32 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2019-06-15 14:18:45 [scrapy.core.scraper] ERROR: Spider error processing <GET https://bx88222.com/html/23919/> (referer: https://bx88222.com/html/23919/)
Traceback (most recent call last):
  File "C:\Users\ltf\AppData\Local\Programs\Python\Python36\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\ltf\AppData\Local\Programs\Python\Python36\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "G:\pythonAI\爬虫大全\hmovie\hmovie\middlewares.py", line 35, in process_spider_output
    for i in result:
  File "C:\Users\ltf\AppData\Local\Programs\Python\Python36\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\ltf\AppData\Local\Programs\Python\Python36\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\ltf\AppData\Local\Programs\Python\Python36\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "G:\pythonAI\爬虫大全\hmovie\hmovie\spiders\hmovieurl.py", line 57, in next_page
    f.write(item['mp4url']+','+item['biaoti']+','+item['shichang']+','+item['riqi']+'\n')
TypeError: must be str, not NoneType
2019-06-15 14:18:46 [scrapy.core.scraper] ERROR: Spider error processing <GET https://bx88222.com/html/23791/> (referer: https://bx88222.com/html/23791/)
Traceback (most recent call last):
  File "C:\Users\ltf\AppData\Local\Programs\Python\Python36\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\ltf\AppData\Local\Programs\Python\Python36\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "G:\pythonAI\爬虫大全\hmovie\hmovie\middlewares.py", line 35, in process_spider_output
    for i in result:
  File "C:\Users\ltf\AppData\Local\Programs\Python\Python36\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\ltf\AppData\Local\Programs\Python\Python36\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\ltf\AppData\Local\Programs\Python\Python36\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "G:\pythonAI\爬虫大全\hmovie\hmovie\spiders\hmovieurl.py", line 57, in next_page
    f.write(item['mp4url']+','+item['biaoti']+','+item['shichang']+','+item['riqi']+'\n')
TypeError: must be str, not NoneType
2019-06-15 14:19:50 [scrapy.utils.log] INFO: Scrapy 1.6.0 started (bot: hmovie)
2019-06-15 14:19:50 [scrapy.utils.log] INFO: Versions: lxml 4.3.4.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.5.1, w3lib 1.20.0, Twisted 18.4.0, Python 3.6.5 (v3.6.5:f59c0932b4, Mar 28 2018, 17:00:18) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 19.0.0 (OpenSSL 1.1.0i  14 Aug 2018), cryptography 2.3.1, Platform Windows-10-10.0.17763-SP0
2019-06-15 14:19:50 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'hmovie', 'LOG_FILE': 'hmovie.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'hmovie.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['hmovie.spiders']}
2019-06-15 14:19:50 [scrapy.extensions.telnet] INFO: Telnet Password: 8894815cf1a50430
2019-06-15 14:19:50 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2019-06-15 14:19:52 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'hmovie.rotate_useragent.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'hmovie.middlewares.HmovieDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-06-15 14:19:52 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'hmovie.middlewares.HmovieSpiderMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-06-15 14:19:52 [scrapy.middleware] INFO: Enabled item pipelines:
['hmovie.pipelines.HmoviePipeline']
2019-06-15 14:19:52 [scrapy.core.engine] INFO: Spider opened
2019-06-15 14:19:52 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-06-15 14:19:52 [hmovieurl] INFO: Spider opened: hmovieurl
2019-06-15 14:19:52 [py.warnings] WARNING: C:\Users\ltf\AppData\Local\Programs\Python\Python36\lib\site-packages\scrapy\spidermiddlewares\offsite.py:61: URLWarning: allowed_domains accepts only domains, not URLs. Ignoring URL entry https://bx88222.com in allowed_domains.
  warnings.warn(message, URLWarning)

2019-06-15 14:19:52 [hmovieurl] INFO: Spider opened: hmovieurl
2019-06-15 14:19:52 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2019-06-15 14:20:22 [scrapy.core.scraper] ERROR: Spider error processing <GET https://bx88222.com/html/23919/> (referer: https://bx88222.com/html/23919/)
Traceback (most recent call last):
  File "C:\Users\ltf\AppData\Local\Programs\Python\Python36\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\ltf\AppData\Local\Programs\Python\Python36\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "G:\pythonAI\爬虫大全\hmovie\hmovie\middlewares.py", line 35, in process_spider_output
    for i in result:
  File "C:\Users\ltf\AppData\Local\Programs\Python\Python36\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\ltf\AppData\Local\Programs\Python\Python36\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\ltf\AppData\Local\Programs\Python\Python36\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "G:\pythonAI\爬虫大全\hmovie\hmovie\spiders\hmovieurl.py", line 57, in next_page
    f.write(item['mp4url']+','+item['biaoti']+','+item['shichang']+','+item['riqi']+'\n')
TypeError: must be str, not NoneType
2019-06-15 14:20:26 [scrapy.core.scraper] ERROR: Spider error processing <GET https://bx88222.com/html/23791/> (referer: https://bx88222.com/html/23791/)
Traceback (most recent call last):
  File "C:\Users\ltf\AppData\Local\Programs\Python\Python36\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\ltf\AppData\Local\Programs\Python\Python36\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "G:\pythonAI\爬虫大全\hmovie\hmovie\middlewares.py", line 35, in process_spider_output
    for i in result:
  File "C:\Users\ltf\AppData\Local\Programs\Python\Python36\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\ltf\AppData\Local\Programs\Python\Python36\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\ltf\AppData\Local\Programs\Python\Python36\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "G:\pythonAI\爬虫大全\hmovie\hmovie\spiders\hmovieurl.py", line 57, in next_page
    f.write(item['mp4url']+','+item['biaoti']+','+item['shichang']+','+item['riqi']+'\n')
TypeError: must be str, not NoneType
2019-06-15 14:20:27 [scrapy.core.scraper] ERROR: Spider error processing <GET https://bx88222.com/html/23891/> (referer: https://bx88222.com/html/23891/)
Traceback (most recent call last):
  File "C:\Users\ltf\AppData\Local\Programs\Python\Python36\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\ltf\AppData\Local\Programs\Python\Python36\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "G:\pythonAI\爬虫大全\hmovie\hmovie\middlewares.py", line 35, in process_spider_output
    for i in result:
  File "C:\Users\ltf\AppData\Local\Programs\Python\Python36\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\ltf\AppData\Local\Programs\Python\Python36\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\ltf\AppData\Local\Programs\Python\Python36\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "G:\pythonAI\爬虫大全\hmovie\hmovie\spiders\hmovieurl.py", line 57, in next_page
    f.write(item['mp4url']+','+item['biaoti']+','+item['shichang']+','+item['riqi']+'\n')
TypeError: must be str, not NoneType
2019-06-15 14:20:37 [scrapy.core.scraper] ERROR: Spider error processing <GET https://bx88222.com/html/23669/> (referer: https://bx88222.com/html/23669/)
Traceback (most recent call last):
  File "C:\Users\ltf\AppData\Local\Programs\Python\Python36\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\ltf\AppData\Local\Programs\Python\Python36\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "G:\pythonAI\爬虫大全\hmovie\hmovie\middlewares.py", line 35, in process_spider_output
    for i in result:
  File "C:\Users\ltf\AppData\Local\Programs\Python\Python36\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\ltf\AppData\Local\Programs\Python\Python36\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\ltf\AppData\Local\Programs\Python\Python36\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "G:\pythonAI\爬虫大全\hmovie\hmovie\spiders\hmovieurl.py", line 57, in next_page
    f.write(item['mp4url']+','+item['biaoti']+','+item['shichang']+','+item['riqi']+'\n')
TypeError: must be str, not NoneType
2019-06-15 14:20:40 [scrapy.core.scraper] ERROR: Spider error processing <GET https://bx88222.com/html/23646/> (referer: https://bx88222.com/html/23646/)
Traceback (most recent call last):
  File "C:\Users\ltf\AppData\Local\Programs\Python\Python36\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\ltf\AppData\Local\Programs\Python\Python36\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "G:\pythonAI\爬虫大全\hmovie\hmovie\middlewares.py", line 35, in process_spider_output
    for i in result:
  File "C:\Users\ltf\AppData\Local\Programs\Python\Python36\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\ltf\AppData\Local\Programs\Python\Python36\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\ltf\AppData\Local\Programs\Python\Python36\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "G:\pythonAI\爬虫大全\hmovie\hmovie\spiders\hmovieurl.py", line 57, in next_page
    f.write(item['mp4url']+','+item['biaoti']+','+item['shichang']+','+item['riqi']+'\n')
TypeError: must be str, not NoneType
2019-06-15 14:20:52 [scrapy.extensions.logstats] INFO: Crawled 990 pages (at 990 pages/min), scraped 463 items (at 463 items/min)
2019-06-15 14:21:15 [scrapy.core.scraper] ERROR: Spider error processing <GET https://bx88222.com/html/23517/> (referer: https://bx88222.com/html/23517/)
Traceback (most recent call last):
  File "C:\Users\ltf\AppData\Local\Programs\Python\Python36\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\ltf\AppData\Local\Programs\Python\Python36\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "G:\pythonAI\爬虫大全\hmovie\hmovie\middlewares.py", line 35, in process_spider_output
    for i in result:
  File "C:\Users\ltf\AppData\Local\Programs\Python\Python36\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\ltf\AppData\Local\Programs\Python\Python36\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\ltf\AppData\Local\Programs\Python\Python36\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "G:\pythonAI\爬虫大全\hmovie\hmovie\spiders\hmovieurl.py", line 57, in next_page
    f.write(item['mp4url']+','+item['biaoti']+','+item['shichang']+','+item['riqi']+'\n')
TypeError: must be str, not NoneType
2019-06-15 14:21:17 [scrapy.core.scraper] ERROR: Spider error processing <GET https://bx88222.com/html/23493/> (referer: https://bx88222.com/html/23493/)
Traceback (most recent call last):
  File "C:\Users\ltf\AppData\Local\Programs\Python\Python36\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\ltf\AppData\Local\Programs\Python\Python36\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "G:\pythonAI\爬虫大全\hmovie\hmovie\middlewares.py", line 35, in process_spider_output
    for i in result:
  File "C:\Users\ltf\AppData\Local\Programs\Python\Python36\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\ltf\AppData\Local\Programs\Python\Python36\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\ltf\AppData\Local\Programs\Python\Python36\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "G:\pythonAI\爬虫大全\hmovie\hmovie\spiders\hmovieurl.py", line 57, in next_page
    f.write(item['mp4url']+','+item['biaoti']+','+item['shichang']+','+item['riqi']+'\n')
TypeError: must be str, not NoneType
2019-06-15 14:21:52 [scrapy.extensions.logstats] INFO: Crawled 2479 pages (at 1489 pages/min), scraped 1187 items (at 724 items/min)
2019-06-15 14:22:04 [scrapy.core.scraper] ERROR: Spider error processing <GET https://bx88222.com/html/22797/> (referer: https://bx88222.com/html/22797/)
Traceback (most recent call last):
  File "C:\Users\ltf\AppData\Local\Programs\Python\Python36\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\ltf\AppData\Local\Programs\Python\Python36\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "G:\pythonAI\爬虫大全\hmovie\hmovie\middlewares.py", line 35, in process_spider_output
    for i in result:
  File "C:\Users\ltf\AppData\Local\Programs\Python\Python36\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\ltf\AppData\Local\Programs\Python\Python36\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\ltf\AppData\Local\Programs\Python\Python36\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "G:\pythonAI\爬虫大全\hmovie\hmovie\spiders\hmovieurl.py", line 57, in next_page
    f.write(item['mp4url']+','+item['biaoti']+','+item['shichang']+','+item['riqi']+'\n')
TypeError: must be str, not NoneType
2019-06-15 14:22:04 [scrapy.core.scraper] ERROR: Spider error processing <GET https://bx88222.com/html/22193/> (referer: https://bx88222.com/html/22193/)
Traceback (most recent call last):
  File "C:\Users\ltf\AppData\Local\Programs\Python\Python36\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\ltf\AppData\Local\Programs\Python\Python36\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "G:\pythonAI\爬虫大全\hmovie\hmovie\middlewares.py", line 35, in process_spider_output
    for i in result:
  File "C:\Users\ltf\AppData\Local\Programs\Python\Python36\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\ltf\AppData\Local\Programs\Python\Python36\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\ltf\AppData\Local\Programs\Python\Python36\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "G:\pythonAI\爬虫大全\hmovie\hmovie\spiders\hmovieurl.py", line 57, in next_page
    f.write(item['mp4url']+','+item['biaoti']+','+item['shichang']+','+item['riqi']+'\n')
TypeError: must be str, not NoneType
2019-06-15 14:22:04 [scrapy.core.scraper] ERROR: Spider error processing <GET https://bx88222.com/html/22196/> (referer: https://bx88222.com/html/22196/)
Traceback (most recent call last):
  File "C:\Users\ltf\AppData\Local\Programs\Python\Python36\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\ltf\AppData\Local\Programs\Python\Python36\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "G:\pythonAI\爬虫大全\hmovie\hmovie\middlewares.py", line 35, in process_spider_output
    for i in result:
  File "C:\Users\ltf\AppData\Local\Programs\Python\Python36\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\ltf\AppData\Local\Programs\Python\Python36\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\ltf\AppData\Local\Programs\Python\Python36\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "G:\pythonAI\爬虫大全\hmovie\hmovie\spiders\hmovieurl.py", line 57, in next_page
    f.write(item['mp4url']+','+item['biaoti']+','+item['shichang']+','+item['riqi']+'\n')
TypeError: must be str, not NoneType
2019-06-15 14:22:04 [scrapy.core.scraper] ERROR: Spider error processing <GET https://bx88222.com/html/22319/> (referer: https://bx88222.com/html/22319/)
Traceback (most recent call last):
  File "C:\Users\ltf\AppData\Local\Programs\Python\Python36\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\ltf\AppData\Local\Programs\Python\Python36\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "G:\pythonAI\爬虫大全\hmovie\hmovie\middlewares.py", line 35, in process_spider_output
    for i in result:
  File "C:\Users\ltf\AppData\Local\Programs\Python\Python36\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\ltf\AppData\Local\Programs\Python\Python36\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\ltf\AppData\Local\Programs\Python\Python36\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "G:\pythonAI\爬虫大全\hmovie\hmovie\spiders\hmovieurl.py", line 57, in next_page
    f.write(item['mp4url']+','+item['biaoti']+','+item['shichang']+','+item['riqi']+'\n')
TypeError: must be str, not NoneType
2019-06-15 14:22:04 [scrapy.core.scraper] ERROR: Spider error processing <GET https://bx88222.com/html/22796/> (referer: https://bx88222.com/html/22796/)
Traceback (most recent call last):
  File "C:\Users\ltf\AppData\Local\Programs\Python\Python36\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\ltf\AppData\Local\Programs\Python\Python36\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "G:\pythonAI\爬虫大全\hmovie\hmovie\middlewares.py", line 35, in process_spider_output
    for i in result:
  File "C:\Users\ltf\AppData\Local\Programs\Python\Python36\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\ltf\AppData\Local\Programs\Python\Python36\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\ltf\AppData\Local\Programs\Python\Python36\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "G:\pythonAI\爬虫大全\hmovie\hmovie\spiders\hmovieurl.py", line 57, in next_page
    f.write(item['mp4url']+','+item['biaoti']+','+item['shichang']+','+item['riqi']+'\n')
TypeError: must be str, not NoneType
2019-06-15 14:22:04 [scrapy.core.scraper] ERROR: Spider error processing <GET https://bx88222.com/html/22188/> (referer: https://bx88222.com/html/22188/)
Traceback (most recent call last):
  File "C:\Users\ltf\AppData\Local\Programs\Python\Python36\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\ltf\AppData\Local\Programs\Python\Python36\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "G:\pythonAI\爬虫大全\hmovie\hmovie\middlewares.py", line 35, in process_spider_output
    for i in result:
  File "C:\Users\ltf\AppData\Local\Programs\Python\Python36\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\ltf\AppData\Local\Programs\Python\Python36\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\ltf\AppData\Local\Programs\Python\Python36\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "G:\pythonAI\爬虫大全\hmovie\hmovie\spiders\hmovieurl.py", line 57, in next_page
    f.write(item['mp4url']+','+item['biaoti']+','+item['shichang']+','+item['riqi']+'\n')
TypeError: must be str, not NoneType
2019-06-15 14:22:04 [scrapy.core.scraper] ERROR: Spider error processing <GET https://bx88222.com/html/22318/> (referer: https://bx88222.com/html/22318/)
Traceback (most recent call last):
  File "C:\Users\ltf\AppData\Local\Programs\Python\Python36\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\ltf\AppData\Local\Programs\Python\Python36\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "G:\pythonAI\爬虫大全\hmovie\hmovie\middlewares.py", line 35, in process_spider_output
    for i in result:
  File "C:\Users\ltf\AppData\Local\Programs\Python\Python36\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\ltf\AppData\Local\Programs\Python\Python36\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\ltf\AppData\Local\Programs\Python\Python36\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "G:\pythonAI\爬虫大全\hmovie\hmovie\spiders\hmovieurl.py", line 57, in next_page
    f.write(item['mp4url']+','+item['biaoti']+','+item['shichang']+','+item['riqi']+'\n')
TypeError: must be str, not NoneType
2019-06-15 14:22:04 [scrapy.core.scraper] ERROR: Spider error processing <GET https://bx88222.com/html/22185/> (referer: https://bx88222.com/html/22185/)
Traceback (most recent call last):
  File "C:\Users\ltf\AppData\Local\Programs\Python\Python36\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\ltf\AppData\Local\Programs\Python\Python36\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "G:\pythonAI\爬虫大全\hmovie\hmovie\middlewares.py", line 35, in process_spider_output
    for i in result:
  File "C:\Users\ltf\AppData\Local\Programs\Python\Python36\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\ltf\AppData\Local\Programs\Python\Python36\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\ltf\AppData\Local\Programs\Python\Python36\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "G:\pythonAI\爬虫大全\hmovie\hmovie\spiders\hmovieurl.py", line 57, in next_page
    f.write(item['mp4url']+','+item['biaoti']+','+item['shichang']+','+item['riqi']+'\n')
TypeError: must be str, not NoneType
2019-06-15 14:22:05 [scrapy.core.scraper] ERROR: Spider error processing <GET https://bx88222.com/html/22179/> (referer: https://bx88222.com/html/22179/)
Traceback (most recent call last):
  File "C:\Users\ltf\AppData\Local\Programs\Python\Python36\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\ltf\AppData\Local\Programs\Python\Python36\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "G:\pythonAI\爬虫大全\hmovie\hmovie\middlewares.py", line 35, in process_spider_output
    for i in result:
  File "C:\Users\ltf\AppData\Local\Programs\Python\Python36\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\ltf\AppData\Local\Programs\Python\Python36\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\ltf\AppData\Local\Programs\Python\Python36\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "G:\pythonAI\爬虫大全\hmovie\hmovie\spiders\hmovieurl.py", line 57, in next_page
    f.write(item['mp4url']+','+item['biaoti']+','+item['shichang']+','+item['riqi']+'\n')
TypeError: must be str, not NoneType
2019-06-15 14:22:05 [scrapy.core.scraper] ERROR: Spider error processing <GET https://bx88222.com/html/22177/> (referer: https://bx88222.com/html/22177/)
Traceback (most recent call last):
  File "C:\Users\ltf\AppData\Local\Programs\Python\Python36\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\ltf\AppData\Local\Programs\Python\Python36\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "G:\pythonAI\爬虫大全\hmovie\hmovie\middlewares.py", line 35, in process_spider_output
    for i in result:
  File "C:\Users\ltf\AppData\Local\Programs\Python\Python36\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\ltf\AppData\Local\Programs\Python\Python36\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\ltf\AppData\Local\Programs\Python\Python36\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "G:\pythonAI\爬虫大全\hmovie\hmovie\spiders\hmovieurl.py", line 57, in next_page
    f.write(item['mp4url']+','+item['biaoti']+','+item['shichang']+','+item['riqi']+'\n')
TypeError: must be str, not NoneType
2019-06-15 14:22:05 [scrapy.core.scraper] ERROR: Spider error processing <GET https://bx88222.com/html/22176/> (referer: https://bx88222.com/html/22176/)
Traceback (most recent call last):
  File "C:\Users\ltf\AppData\Local\Programs\Python\Python36\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\ltf\AppData\Local\Programs\Python\Python36\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "G:\pythonAI\爬虫大全\hmovie\hmovie\middlewares.py", line 35, in process_spider_output
    for i in result:
  File "C:\Users\ltf\AppData\Local\Programs\Python\Python36\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\ltf\AppData\Local\Programs\Python\Python36\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\ltf\AppData\Local\Programs\Python\Python36\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "G:\pythonAI\爬虫大全\hmovie\hmovie\spiders\hmovieurl.py", line 57, in next_page
    f.write(item['mp4url']+','+item['biaoti']+','+item['shichang']+','+item['riqi']+'\n')
TypeError: must be str, not NoneType
2019-06-15 14:22:41 [scrapy.core.scraper] ERROR: Spider error processing <GET https://bx88222.com/> (referer: https://bx88222.com/)
Traceback (most recent call last):
  File "C:\Users\ltf\AppData\Local\Programs\Python\Python36\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\ltf\AppData\Local\Programs\Python\Python36\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "G:\pythonAI\爬虫大全\hmovie\hmovie\middlewares.py", line 35, in process_spider_output
    for i in result:
  File "C:\Users\ltf\AppData\Local\Programs\Python\Python36\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\ltf\AppData\Local\Programs\Python\Python36\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\ltf\AppData\Local\Programs\Python\Python36\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "G:\pythonAI\爬虫大全\hmovie\hmovie\spiders\hmovieurl.py", line 57, in next_page
    f.write(item['mp4url']+','+item['biaoti']+','+item['shichang']+','+item['riqi']+'\n')
TypeError: unsupported operand type(s) for +: 'NoneType' and 'str'
2019-06-15 14:22:52 [scrapy.extensions.logstats] INFO: Crawled 3937 pages (at 1458 pages/min), scraped 1879 items (at 692 items/min)
2019-06-15 14:23:48 [scrapy.core.scraper] ERROR: Spider error processing <GET https://bx88222.com/html/21255/> (referer: https://bx88222.com/html/21255/)
Traceback (most recent call last):
  File "C:\Users\ltf\AppData\Local\Programs\Python\Python36\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\ltf\AppData\Local\Programs\Python\Python36\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "G:\pythonAI\爬虫大全\hmovie\hmovie\middlewares.py", line 35, in process_spider_output
    for i in result:
  File "C:\Users\ltf\AppData\Local\Programs\Python\Python36\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\ltf\AppData\Local\Programs\Python\Python36\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\ltf\AppData\Local\Programs\Python\Python36\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "G:\pythonAI\爬虫大全\hmovie\hmovie\spiders\hmovieurl.py", line 57, in next_page
    f.write(item['mp4url']+','+item['biaoti']+','+item['shichang']+','+item['riqi']+'\n')
TypeError: must be str, not NoneType
2019-06-15 14:23:52 [scrapy.extensions.logstats] INFO: Crawled 5377 pages (at 1440 pages/min), scraped 2581 items (at 702 items/min)
2019-06-15 14:24:03 [scrapy.core.scraper] ERROR: Spider error processing <GET https://bx88222.com/html/20566/> (referer: https://bx88222.com/html/20566/)
Traceback (most recent call last):
  File "C:\Users\ltf\AppData\Local\Programs\Python\Python36\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\ltf\AppData\Local\Programs\Python\Python36\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "G:\pythonAI\爬虫大全\hmovie\hmovie\middlewares.py", line 35, in process_spider_output
    for i in result:
  File "C:\Users\ltf\AppData\Local\Programs\Python\Python36\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\ltf\AppData\Local\Programs\Python\Python36\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\ltf\AppData\Local\Programs\Python\Python36\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "G:\pythonAI\爬虫大全\hmovie\hmovie\spiders\hmovieurl.py", line 57, in next_page
    f.write(item['mp4url']+','+item['biaoti']+','+item['shichang']+','+item['riqi']+'\n')
TypeError: must be str, not NoneType
2019-06-15 14:24:52 [scrapy.extensions.logstats] INFO: Crawled 6829 pages (at 1452 pages/min), scraped 3282 items (at 701 items/min)
2019-06-15 14:25:52 [scrapy.extensions.logstats] INFO: Crawled 8216 pages (at 1387 pages/min), scraped 3954 items (at 672 items/min)
2019-06-15 14:26:13 [scrapy.core.scraper] ERROR: Spider error processing <GET https://bx88222.com/html/19002/> (referer: https://bx88222.com/html/19002/)
Traceback (most recent call last):
  File "C:\Users\ltf\AppData\Local\Programs\Python\Python36\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\ltf\AppData\Local\Programs\Python\Python36\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "G:\pythonAI\爬虫大全\hmovie\hmovie\middlewares.py", line 35, in process_spider_output
    for i in result:
  File "C:\Users\ltf\AppData\Local\Programs\Python\Python36\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\ltf\AppData\Local\Programs\Python\Python36\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\ltf\AppData\Local\Programs\Python\Python36\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "G:\pythonAI\爬虫大全\hmovie\hmovie\spiders\hmovieurl.py", line 57, in next_page
    f.write(item['mp4url']+','+item['biaoti']+','+item['shichang']+','+item['riqi']+'\n')
TypeError: must be str, not NoneType
2019-06-15 14:26:19 [scrapy.core.scraper] ERROR: Spider error processing <GET https://bx88222.com/html/19048/> (referer: https://bx88222.com/html/19048/)
Traceback (most recent call last):
  File "C:\Users\ltf\AppData\Local\Programs\Python\Python36\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\ltf\AppData\Local\Programs\Python\Python36\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "G:\pythonAI\爬虫大全\hmovie\hmovie\middlewares.py", line 35, in process_spider_output
    for i in result:
  File "C:\Users\ltf\AppData\Local\Programs\Python\Python36\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\ltf\AppData\Local\Programs\Python\Python36\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\ltf\AppData\Local\Programs\Python\Python36\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "G:\pythonAI\爬虫大全\hmovie\hmovie\spiders\hmovieurl.py", line 57, in next_page
    f.write(item['mp4url']+','+item['biaoti']+','+item['shichang']+','+item['riqi']+'\n')
TypeError: must be str, not NoneType
2019-06-15 14:26:21 [scrapy.core.scraper] ERROR: Spider error processing <GET https://bx88222.com/html/18623/> (referer: https://bx88222.com/html/18623/)
Traceback (most recent call last):
  File "C:\Users\ltf\AppData\Local\Programs\Python\Python36\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\ltf\AppData\Local\Programs\Python\Python36\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "G:\pythonAI\爬虫大全\hmovie\hmovie\middlewares.py", line 35, in process_spider_output
    for i in result:
  File "C:\Users\ltf\AppData\Local\Programs\Python\Python36\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\ltf\AppData\Local\Programs\Python\Python36\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\ltf\AppData\Local\Programs\Python\Python36\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "G:\pythonAI\爬虫大全\hmovie\hmovie\spiders\hmovieurl.py", line 57, in next_page
    f.write(item['mp4url']+','+item['biaoti']+','+item['shichang']+','+item['riqi']+'\n')
TypeError: must be str, not NoneType
2019-06-15 14:26:41 [scrapy.core.scraper] ERROR: Spider error processing <GET https://bx88222.com/html/18966/> (referer: https://bx88222.com/html/18966/)
Traceback (most recent call last):
  File "C:\Users\ltf\AppData\Local\Programs\Python\Python36\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\ltf\AppData\Local\Programs\Python\Python36\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "G:\pythonAI\爬虫大全\hmovie\hmovie\middlewares.py", line 35, in process_spider_output
    for i in result:
  File "C:\Users\ltf\AppData\Local\Programs\Python\Python36\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\ltf\AppData\Local\Programs\Python\Python36\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\ltf\AppData\Local\Programs\Python\Python36\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "G:\pythonAI\爬虫大全\hmovie\hmovie\spiders\hmovieurl.py", line 57, in next_page
    f.write(item['mp4url']+','+item['biaoti']+','+item['shichang']+','+item['riqi']+'\n')
TypeError: must be str, not NoneType
2019-06-15 14:26:44 [scrapy.core.scraper] ERROR: Spider error processing <GET https://bx88222.com/html/19021/> (referer: https://bx88222.com/html/19021/)
Traceback (most recent call last):
  File "C:\Users\ltf\AppData\Local\Programs\Python\Python36\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\ltf\AppData\Local\Programs\Python\Python36\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "G:\pythonAI\爬虫大全\hmovie\hmovie\middlewares.py", line 35, in process_spider_output
    for i in result:
  File "C:\Users\ltf\AppData\Local\Programs\Python\Python36\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\ltf\AppData\Local\Programs\Python\Python36\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\ltf\AppData\Local\Programs\Python\Python36\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "G:\pythonAI\爬虫大全\hmovie\hmovie\spiders\hmovieurl.py", line 57, in next_page
    f.write(item['mp4url']+','+item['biaoti']+','+item['shichang']+','+item['riqi']+'\n')
TypeError: must be str, not NoneType
2019-06-15 14:26:52 [scrapy.extensions.logstats] INFO: Crawled 9577 pages (at 1361 pages/min), scraped 4601 items (at 647 items/min)
2019-06-15 14:27:20 [scrapy.core.scraper] ERROR: Spider error processing <GET https://bx88222.com/html/18672/> (referer: https://bx88222.com/html/18672/)
Traceback (most recent call last):
  File "C:\Users\ltf\AppData\Local\Programs\Python\Python36\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\ltf\AppData\Local\Programs\Python\Python36\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "G:\pythonAI\爬虫大全\hmovie\hmovie\middlewares.py", line 35, in process_spider_output
    for i in result:
  File "C:\Users\ltf\AppData\Local\Programs\Python\Python36\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\ltf\AppData\Local\Programs\Python\Python36\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\ltf\AppData\Local\Programs\Python\Python36\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "G:\pythonAI\爬虫大全\hmovie\hmovie\spiders\hmovieurl.py", line 57, in next_page
    f.write(item['mp4url']+','+item['biaoti']+','+item['shichang']+','+item['riqi']+'\n')
TypeError: must be str, not NoneType
2019-06-15 14:27:52 [scrapy.extensions.logstats] INFO: Crawled 10808 pages (at 1231 pages/min), scraped 5197 items (at 596 items/min)
2019-06-15 14:27:59 [scrapy.core.scraper] ERROR: Spider error processing <GET https://bx88222.com/html/8080/> (referer: https://bx88222.com/html/8080/)
Traceback (most recent call last):
  File "C:\Users\ltf\AppData\Local\Programs\Python\Python36\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\ltf\AppData\Local\Programs\Python\Python36\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "G:\pythonAI\爬虫大全\hmovie\hmovie\middlewares.py", line 35, in process_spider_output
    for i in result:
  File "C:\Users\ltf\AppData\Local\Programs\Python\Python36\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\ltf\AppData\Local\Programs\Python\Python36\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\ltf\AppData\Local\Programs\Python\Python36\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "G:\pythonAI\爬虫大全\hmovie\hmovie\spiders\hmovieurl.py", line 57, in next_page
    f.write(item['mp4url']+','+item['biaoti']+','+item['shichang']+','+item['riqi']+'\n')
TypeError: must be str, not NoneType
2019-06-15 14:28:02 [scrapy.core.scraper] ERROR: Spider error processing <GET https://bx88222.com/html/17840/> (referer: https://bx88222.com/html/17840/)
Traceback (most recent call last):
  File "C:\Users\ltf\AppData\Local\Programs\Python\Python36\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\ltf\AppData\Local\Programs\Python\Python36\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "G:\pythonAI\爬虫大全\hmovie\hmovie\middlewares.py", line 35, in process_spider_output
    for i in result:
  File "C:\Users\ltf\AppData\Local\Programs\Python\Python36\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\ltf\AppData\Local\Programs\Python\Python36\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\ltf\AppData\Local\Programs\Python\Python36\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "G:\pythonAI\爬虫大全\hmovie\hmovie\spiders\hmovieurl.py", line 57, in next_page
    f.write(item['mp4url']+','+item['biaoti']+','+item['shichang']+','+item['riqi']+'\n')
TypeError: must be str, not NoneType
2019-06-15 14:28:52 [scrapy.extensions.logstats] INFO: Crawled 12283 pages (at 1475 pages/min), scraped 5907 items (at 710 items/min)
2019-06-15 14:29:52 [scrapy.extensions.logstats] INFO: Crawled 13697 pages (at 1414 pages/min), scraped 6603 items (at 696 items/min)
2019-06-15 14:30:52 [scrapy.extensions.logstats] INFO: Crawled 15044 pages (at 1347 pages/min), scraped 7257 items (at 654 items/min)
2019-06-15 14:31:52 [scrapy.extensions.logstats] INFO: Crawled 16484 pages (at 1440 pages/min), scraped 7953 items (at 696 items/min)
2019-06-15 14:32:52 [scrapy.extensions.logstats] INFO: Crawled 17923 pages (at 1439 pages/min), scraped 8647 items (at 694 items/min)
2019-06-15 14:33:52 [scrapy.extensions.logstats] INFO: Crawled 18926 pages (at 1003 pages/min), scraped 9137 items (at 490 items/min)
2019-06-15 14:34:52 [scrapy.extensions.logstats] INFO: Crawled 20393 pages (at 1467 pages/min), scraped 9847 items (at 710 items/min)
2019-06-15 14:35:52 [scrapy.extensions.logstats] INFO: Crawled 21319 pages (at 926 pages/min), scraped 10302 items (at 455 items/min)
2019-06-15 14:36:52 [scrapy.extensions.logstats] INFO: Crawled 22332 pages (at 1013 pages/min), scraped 10789 items (at 487 items/min)
2019-06-15 14:37:52 [scrapy.extensions.logstats] INFO: Crawled 23732 pages (at 1400 pages/min), scraped 11465 items (at 676 items/min)
2019-06-15 14:38:52 [scrapy.extensions.logstats] INFO: Crawled 25101 pages (at 1369 pages/min), scraped 12129 items (at 664 items/min)
2019-06-15 14:39:52 [scrapy.extensions.logstats] INFO: Crawled 26488 pages (at 1387 pages/min), scraped 12806 items (at 677 items/min)
2019-06-15 14:40:52 [scrapy.extensions.logstats] INFO: Crawled 27935 pages (at 1447 pages/min), scraped 13500 items (at 694 items/min)
2019-06-15 14:41:52 [scrapy.extensions.logstats] INFO: Crawled 29420 pages (at 1485 pages/min), scraped 14222 items (at 722 items/min)
2019-06-15 14:42:52 [scrapy.extensions.logstats] INFO: Crawled 30663 pages (at 1243 pages/min), scraped 14827 items (at 605 items/min)
2019-06-15 14:43:52 [scrapy.extensions.logstats] INFO: Crawled 32115 pages (at 1452 pages/min), scraped 15530 items (at 703 items/min)
2019-06-15 14:44:30 [scrapy.core.engine] INFO: Closing spider (finished)
2019-06-15 14:44:30 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 11466370,
 'downloader/request_count': 32970,
 'downloader/request_method_count/GET': 32970,
 'downloader/response_bytes': 220648190,
 'downloader/response_count': 32970,
 'downloader/response_status_count/200': 32968,
 'downloader/response_status_count/404': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2019, 6, 15, 6, 44, 30, 213447),
 'item_scraped_count': 15955,
 'log_count/ERROR': 29,
 'log_count/INFO': 35,
 'log_count/WARNING': 1,
 'request_depth_max': 2,
 'response_received_count': 32968,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/200': 1,
 'scheduler/dequeued': 32969,
 'scheduler/dequeued/memory': 32969,
 'scheduler/enqueued': 32969,
 'scheduler/enqueued/memory': 32969,
 'spider_exceptions/TypeError': 29,
 'start_time': datetime.datetime(2019, 6, 15, 6, 19, 52, 768201)}
2019-06-15 14:44:30 [scrapy.core.engine] INFO: Spider closed (finished)
