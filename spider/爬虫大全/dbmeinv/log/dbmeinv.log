2019-06-16 17:13:17 [scrapy.utils.log] INFO: Scrapy 1.6.0 started (bot: dbmeinv)
2019-06-16 17:13:17 [scrapy.utils.log] INFO: Versions: lxml 4.3.4.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.5.1, w3lib 1.20.0, Twisted 18.4.0, Python 3.6.5 (v3.6.5:f59c0932b4, Mar 28 2018, 17:00:18) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 19.0.0 (OpenSSL 1.1.0i  14 Aug 2018), cryptography 2.3.1, Platform Windows-10-10.0.17763-SP0
2019-06-16 17:13:17 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'dbmeinv', 'DOWNLOAD_DELAY': 0.5, 'LOG_FILE': 'log/dbmeinv.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'dbmeinv.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['dbmeinv.spiders']}
2019-06-16 17:13:17 [scrapy.extensions.telnet] INFO: Telnet Password: ddf1e806e30068c5
2019-06-16 17:13:17 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2019-06-16 17:13:19 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'dbmeinv.rotate_useragent.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'dbmeinv.middlewares.DbmeinvDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-06-16 17:13:19 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'dbmeinv.middlewares.DbmeinvSpiderMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-06-16 17:13:19 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2019-06-16 17:13:19 [scrapy.core.engine] INFO: Spider opened
2019-06-16 17:13:19 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-06-16 17:13:19 [meinvspider] INFO: Spider opened: meinvspider
2019-06-16 17:13:19 [py.warnings] WARNING: C:\Users\ltf\AppData\Local\Programs\Python\Python36\lib\site-packages\scrapy\spidermiddlewares\offsite.py:61: URLWarning: allowed_domains accepts only domains, not URLs. Ignoring URL entry https://www.dbmeinv.com/ in allowed_domains.
  warnings.warn(message, URLWarning)

2019-06-16 17:13:19 [meinvspider] INFO: Spider opened: meinvspider
2019-06-16 17:13:19 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2019-06-16 17:13:20 [scrapy.core.engine] INFO: Closing spider (finished)
2019-06-16 17:13:20 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 572,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 5121,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2019, 6, 16, 9, 13, 20, 815725),
 'log_count/INFO': 11,
 'log_count/WARNING': 1,
 'response_received_count': 2,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/200': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2019, 6, 16, 9, 13, 19, 453735)}
2019-06-16 17:13:20 [scrapy.core.engine] INFO: Spider closed (finished)
2019-06-16 17:14:15 [scrapy.utils.log] INFO: Scrapy 1.6.0 started (bot: dbmeinv)
2019-06-16 17:14:15 [scrapy.utils.log] INFO: Versions: lxml 4.3.4.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.5.1, w3lib 1.20.0, Twisted 18.4.0, Python 3.6.5 (v3.6.5:f59c0932b4, Mar 28 2018, 17:00:18) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 19.0.0 (OpenSSL 1.1.0i  14 Aug 2018), cryptography 2.3.1, Platform Windows-10-10.0.17763-SP0
2019-06-16 17:14:15 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'dbmeinv', 'DOWNLOAD_DELAY': 0.5, 'LOG_FILE': 'log/dbmeinv.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'dbmeinv.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['dbmeinv.spiders']}
2019-06-16 17:14:15 [scrapy.extensions.telnet] INFO: Telnet Password: fb6531da69136427
2019-06-16 17:14:15 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2019-06-16 17:14:17 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'dbmeinv.rotate_useragent.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'dbmeinv.middlewares.DbmeinvDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-06-16 17:14:17 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'dbmeinv.middlewares.DbmeinvSpiderMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-06-16 17:14:17 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2019-06-16 17:14:17 [scrapy.core.engine] INFO: Spider opened
2019-06-16 17:14:17 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-06-16 17:14:17 [meinvspider] INFO: Spider opened: meinvspider
2019-06-16 17:14:17 [py.warnings] WARNING: C:\Users\ltf\AppData\Local\Programs\Python\Python36\lib\site-packages\scrapy\spidermiddlewares\offsite.py:61: URLWarning: allowed_domains accepts only domains, not URLs. Ignoring URL entry https://www.dbmeinv.com/ in allowed_domains.
  warnings.warn(message, URLWarning)

2019-06-16 17:14:17 [meinvspider] INFO: Spider opened: meinvspider
2019-06-16 17:14:17 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2019-06-16 17:14:18 [scrapy.core.engine] INFO: Closing spider (finished)
2019-06-16 17:14:18 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 573,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 5121,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2019, 6, 16, 9, 14, 18, 398751),
 'log_count/INFO': 11,
 'log_count/WARNING': 1,
 'response_received_count': 2,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/200': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2019, 6, 16, 9, 14, 17, 747735)}
2019-06-16 17:14:18 [scrapy.core.engine] INFO: Spider closed (finished)
2019-06-16 17:18:40 [scrapy.utils.log] INFO: Scrapy 1.6.0 started (bot: dbmeinv)
2019-06-16 17:18:40 [scrapy.utils.log] INFO: Versions: lxml 4.3.4.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.5.1, w3lib 1.20.0, Twisted 18.4.0, Python 3.6.5 (v3.6.5:f59c0932b4, Mar 28 2018, 17:00:18) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 19.0.0 (OpenSSL 1.1.0i  14 Aug 2018), cryptography 2.3.1, Platform Windows-10-10.0.17763-SP0
2019-06-16 17:18:40 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'dbmeinv', 'DOWNLOAD_DELAY': 0.5, 'LOG_FILE': 'log/dbmeinv.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'dbmeinv.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['dbmeinv.spiders']}
2019-06-16 17:18:40 [scrapy.extensions.telnet] INFO: Telnet Password: 466bc5dffd1ebeae
2019-06-16 17:18:40 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2019-06-16 17:18:42 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'dbmeinv.rotate_useragent.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'dbmeinv.middlewares.DbmeinvDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-06-16 17:18:42 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'dbmeinv.middlewares.DbmeinvSpiderMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-06-16 17:18:42 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2019-06-16 17:18:42 [scrapy.core.engine] INFO: Spider opened
2019-06-16 17:18:42 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-06-16 17:18:42 [meinvspider] INFO: Spider opened: meinvspider
2019-06-16 17:18:42 [py.warnings] WARNING: C:\Users\ltf\AppData\Local\Programs\Python\Python36\lib\site-packages\scrapy\spidermiddlewares\offsite.py:61: URLWarning: allowed_domains accepts only domains, not URLs. Ignoring URL entry https://www.dbmeinv.com/ in allowed_domains.
  warnings.warn(message, URLWarning)

2019-06-16 17:18:42 [meinvspider] INFO: Spider opened: meinvspider
2019-06-16 17:18:42 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2019-06-16 17:18:43 [scrapy.core.engine] INFO: Closing spider (finished)
2019-06-16 17:18:43 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 575,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 5121,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2019, 6, 16, 9, 18, 43, 635734),
 'log_count/INFO': 11,
 'log_count/WARNING': 1,
 'response_received_count': 2,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/200': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2019, 6, 16, 9, 18, 42, 536755)}
2019-06-16 17:18:43 [scrapy.core.engine] INFO: Spider closed (finished)
2019-06-16 17:20:24 [scrapy.utils.log] INFO: Scrapy 1.6.0 started (bot: dbmeinv)
2019-06-16 17:20:24 [scrapy.utils.log] INFO: Versions: lxml 4.3.4.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.5.1, w3lib 1.20.0, Twisted 18.4.0, Python 3.6.5 (v3.6.5:f59c0932b4, Mar 28 2018, 17:00:18) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 19.0.0 (OpenSSL 1.1.0i  14 Aug 2018), cryptography 2.3.1, Platform Windows-10-10.0.17763-SP0
2019-06-16 17:20:24 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'dbmeinv', 'DOWNLOAD_DELAY': 0.5, 'LOG_FILE': 'log/dbmeinv.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'dbmeinv.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['dbmeinv.spiders']}
2019-06-16 17:20:24 [scrapy.extensions.telnet] INFO: Telnet Password: 85b60634666c954c
2019-06-16 17:20:24 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2019-06-16 17:20:26 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'dbmeinv.rotate_useragent.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'dbmeinv.middlewares.DbmeinvDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-06-16 17:20:26 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'dbmeinv.middlewares.DbmeinvSpiderMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-06-16 17:20:26 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2019-06-16 17:20:26 [scrapy.core.engine] INFO: Spider opened
2019-06-16 17:20:26 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-06-16 17:20:26 [meinvspider] INFO: Spider opened: meinvspider
2019-06-16 17:20:26 [py.warnings] WARNING: C:\Users\ltf\AppData\Local\Programs\Python\Python36\lib\site-packages\scrapy\spidermiddlewares\offsite.py:61: URLWarning: allowed_domains accepts only domains, not URLs. Ignoring URL entry https://www.dbmeinv.com/ in allowed_domains.
  warnings.warn(message, URLWarning)

2019-06-16 17:20:26 [meinvspider] INFO: Spider opened: meinvspider
2019-06-16 17:20:26 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2019-06-16 17:20:27 [scrapy.core.engine] INFO: Closing spider (finished)
2019-06-16 17:20:27 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 571,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 5121,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2019, 6, 16, 9, 20, 27, 369728),
 'log_count/INFO': 11,
 'log_count/WARNING': 1,
 'response_received_count': 2,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/200': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2019, 6, 16, 9, 20, 26, 454733)}
2019-06-16 17:20:27 [scrapy.core.engine] INFO: Spider closed (finished)
2019-06-16 17:20:45 [scrapy.utils.log] INFO: Scrapy 1.6.0 started (bot: dbmeinv)
2019-06-16 17:20:45 [scrapy.utils.log] INFO: Versions: lxml 4.3.4.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.5.1, w3lib 1.20.0, Twisted 18.4.0, Python 3.6.5 (v3.6.5:f59c0932b4, Mar 28 2018, 17:00:18) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 19.0.0 (OpenSSL 1.1.0i  14 Aug 2018), cryptography 2.3.1, Platform Windows-10-10.0.17763-SP0
2019-06-16 17:20:45 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'dbmeinv', 'DOWNLOAD_DELAY': 0.5, 'LOG_FILE': 'log/dbmeinv.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'dbmeinv.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['dbmeinv.spiders']}
2019-06-16 17:20:45 [scrapy.extensions.telnet] INFO: Telnet Password: 583d587b797c2000
2019-06-16 17:20:45 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2019-06-16 17:20:47 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'dbmeinv.rotate_useragent.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'dbmeinv.middlewares.DbmeinvDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-06-16 17:20:47 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'dbmeinv.middlewares.DbmeinvSpiderMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-06-16 17:20:47 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2019-06-16 17:20:47 [scrapy.core.engine] INFO: Spider opened
2019-06-16 17:20:47 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-06-16 17:20:47 [meinvspider] INFO: Spider opened: meinvspider
2019-06-16 17:20:47 [py.warnings] WARNING: C:\Users\ltf\AppData\Local\Programs\Python\Python36\lib\site-packages\scrapy\spidermiddlewares\offsite.py:61: URLWarning: allowed_domains accepts only domains, not URLs. Ignoring URL entry https://www.dbmeinv.com/ in allowed_domains.
  warnings.warn(message, URLWarning)

2019-06-16 17:20:47 [meinvspider] INFO: Spider opened: meinvspider
2019-06-16 17:20:47 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2019-06-16 17:20:48 [scrapy.core.engine] INFO: Closing spider (finished)
2019-06-16 17:20:48 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 691,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 5121,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2019, 6, 16, 9, 20, 48, 621752),
 'log_count/INFO': 11,
 'log_count/WARNING': 1,
 'response_received_count': 2,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/200': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2019, 6, 16, 9, 20, 47, 693730)}
2019-06-16 17:20:48 [scrapy.core.engine] INFO: Spider closed (finished)
2019-06-16 17:21:51 [scrapy.utils.log] INFO: Scrapy 1.6.0 started (bot: dbmeinv)
2019-06-16 17:21:51 [scrapy.utils.log] INFO: Versions: lxml 4.3.4.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.5.1, w3lib 1.20.0, Twisted 18.4.0, Python 3.6.5 (v3.6.5:f59c0932b4, Mar 28 2018, 17:00:18) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 19.0.0 (OpenSSL 1.1.0i  14 Aug 2018), cryptography 2.3.1, Platform Windows-10-10.0.17763-SP0
2019-06-16 17:21:51 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'dbmeinv', 'DOWNLOAD_DELAY': 0.5, 'LOG_FILE': 'log/dbmeinv.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'dbmeinv.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['dbmeinv.spiders']}
2019-06-16 17:21:51 [scrapy.extensions.telnet] INFO: Telnet Password: bb26077fce7b98a5
2019-06-16 17:21:51 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2019-06-16 17:21:53 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'dbmeinv.rotate_useragent.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'dbmeinv.middlewares.DbmeinvDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-06-16 17:21:53 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'dbmeinv.middlewares.DbmeinvSpiderMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-06-16 17:21:53 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2019-06-16 17:21:53 [scrapy.core.engine] INFO: Spider opened
2019-06-16 17:21:53 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-06-16 17:21:53 [meinvspider] INFO: Spider opened: meinvspider
2019-06-16 17:21:53 [py.warnings] WARNING: C:\Users\ltf\AppData\Local\Programs\Python\Python36\lib\site-packages\scrapy\spidermiddlewares\offsite.py:61: URLWarning: allowed_domains accepts only domains, not URLs. Ignoring URL entry https://www.dbmeinv.com/ in allowed_domains.
  warnings.warn(message, URLWarning)

2019-06-16 17:21:53 [meinvspider] INFO: Spider opened: meinvspider
2019-06-16 17:21:53 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2019-06-16 17:21:54 [scrapy.core.engine] INFO: Closing spider (finished)
2019-06-16 17:21:54 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 692,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 5121,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2019, 6, 16, 9, 21, 54, 712753),
 'log_count/INFO': 11,
 'log_count/WARNING': 1,
 'response_received_count': 2,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/200': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2019, 6, 16, 9, 21, 53, 791730)}
2019-06-16 17:21:54 [scrapy.core.engine] INFO: Spider closed (finished)
2019-06-16 17:22:18 [scrapy.utils.log] INFO: Scrapy 1.6.0 started (bot: dbmeinv)
2019-06-16 17:22:18 [scrapy.utils.log] INFO: Versions: lxml 4.3.4.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.5.1, w3lib 1.20.0, Twisted 18.4.0, Python 3.6.5 (v3.6.5:f59c0932b4, Mar 28 2018, 17:00:18) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 19.0.0 (OpenSSL 1.1.0i  14 Aug 2018), cryptography 2.3.1, Platform Windows-10-10.0.17763-SP0
2019-06-16 17:22:18 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'dbmeinv', 'DOWNLOAD_DELAY': 0.5, 'LOG_FILE': 'log/dbmeinv.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'dbmeinv.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['dbmeinv.spiders']}
2019-06-16 17:22:18 [scrapy.extensions.telnet] INFO: Telnet Password: d523f9d5d8c1065e
2019-06-16 17:22:18 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2019-06-16 17:22:20 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'dbmeinv.rotate_useragent.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'dbmeinv.middlewares.DbmeinvDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-06-16 17:22:20 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'dbmeinv.middlewares.DbmeinvSpiderMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-06-16 17:22:20 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2019-06-16 17:22:20 [scrapy.core.engine] INFO: Spider opened
2019-06-16 17:22:20 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-06-16 17:22:20 [meinvspider] INFO: Spider opened: meinvspider
2019-06-16 17:22:20 [py.warnings] WARNING: C:\Users\ltf\AppData\Local\Programs\Python\Python36\lib\site-packages\scrapy\spidermiddlewares\offsite.py:61: URLWarning: allowed_domains accepts only domains, not URLs. Ignoring URL entry https://www.dbmeinv.com/ in allowed_domains.
  warnings.warn(message, URLWarning)

2019-06-16 17:22:20 [meinvspider] INFO: Spider opened: meinvspider
2019-06-16 17:22:20 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2019-06-16 17:22:21 [scrapy.core.engine] INFO: Closing spider (finished)
2019-06-16 17:22:21 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 573,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 5121,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2019, 6, 16, 9, 22, 21, 555726),
 'log_count/INFO': 11,
 'log_count/WARNING': 1,
 'response_received_count': 2,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/200': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2019, 6, 16, 9, 22, 20, 830753)}
2019-06-16 17:22:21 [scrapy.core.engine] INFO: Spider closed (finished)
2019-06-16 17:28:31 [scrapy.utils.log] INFO: Scrapy 1.6.0 started (bot: dbmeinv)
2019-06-16 17:28:31 [scrapy.utils.log] INFO: Versions: lxml 4.3.4.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.5.1, w3lib 1.20.0, Twisted 18.4.0, Python 3.6.5 (v3.6.5:f59c0932b4, Mar 28 2018, 17:00:18) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 19.0.0 (OpenSSL 1.1.0i  14 Aug 2018), cryptography 2.3.1, Platform Windows-10-10.0.17763-SP0
2019-06-16 17:28:31 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'dbmeinv', 'DOWNLOAD_DELAY': 0.5, 'LOG_FILE': 'log/dbmeinv.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'dbmeinv.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['dbmeinv.spiders']}
2019-06-16 17:28:31 [scrapy.extensions.telnet] INFO: Telnet Password: 5e9c79d7ede4589c
2019-06-16 17:28:31 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2019-06-16 17:28:33 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'dbmeinv.rotate_useragent.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'dbmeinv.middlewares.DbmeinvDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-06-16 17:28:33 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'dbmeinv.middlewares.DbmeinvSpiderMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-06-16 17:28:33 [scrapy.middleware] INFO: Enabled item pipelines:
['dbmeinv.pipelines.DbmeinvPipeline']
2019-06-16 17:28:33 [scrapy.core.engine] INFO: Spider opened
2019-06-16 17:28:33 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-06-16 17:28:33 [meinvspider] INFO: Spider opened: meinvspider
2019-06-16 17:28:33 [py.warnings] WARNING: C:\Users\ltf\AppData\Local\Programs\Python\Python36\lib\site-packages\scrapy\spidermiddlewares\offsite.py:61: URLWarning: allowed_domains accepts only domains, not URLs. Ignoring URL entry https://www.dbmeinv.com/ in allowed_domains.
  warnings.warn(message, URLWarning)

2019-06-16 17:28:33 [meinvspider] INFO: Spider opened: meinvspider
2019-06-16 17:28:33 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2019-06-16 17:28:34 [scrapy.core.engine] INFO: Closing spider (finished)
2019-06-16 17:28:34 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 573,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 5121,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2019, 6, 16, 9, 28, 34, 61756),
 'item_scraped_count': 20,
 'log_count/INFO': 11,
 'log_count/WARNING': 1,
 'response_received_count': 2,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/200': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2019, 6, 16, 9, 28, 33, 126735)}
2019-06-16 17:28:34 [scrapy.core.engine] INFO: Spider closed (finished)
2019-06-16 17:34:05 [scrapy.utils.log] INFO: Scrapy 1.6.0 started (bot: dbmeinv)
2019-06-16 17:34:05 [scrapy.utils.log] INFO: Versions: lxml 4.3.4.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.5.1, w3lib 1.20.0, Twisted 18.4.0, Python 3.6.5 (v3.6.5:f59c0932b4, Mar 28 2018, 17:00:18) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 19.0.0 (OpenSSL 1.1.0i  14 Aug 2018), cryptography 2.3.1, Platform Windows-10-10.0.17763-SP0
2019-06-16 17:34:05 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'dbmeinv', 'DOWNLOAD_DELAY': 0.5, 'LOG_FILE': 'log/dbmeinv.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'dbmeinv.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['dbmeinv.spiders']}
2019-06-16 17:34:05 [scrapy.extensions.telnet] INFO: Telnet Password: 3f2ed24d6d4643bc
2019-06-16 17:34:05 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2019-06-16 17:34:07 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'dbmeinv.rotate_useragent.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'dbmeinv.middlewares.DbmeinvDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-06-16 17:34:07 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'dbmeinv.middlewares.DbmeinvSpiderMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-06-16 17:34:07 [scrapy.middleware] INFO: Enabled item pipelines:
['dbmeinv.pipelines.DbmeinvPipeline']
2019-06-16 17:34:07 [scrapy.core.engine] INFO: Spider opened
2019-06-16 17:34:07 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-06-16 17:34:07 [meinvspider] INFO: Spider opened: meinvspider
2019-06-16 17:34:07 [py.warnings] WARNING: C:\Users\ltf\AppData\Local\Programs\Python\Python36\lib\site-packages\scrapy\spidermiddlewares\offsite.py:61: URLWarning: allowed_domains accepts only domains, not URLs. Ignoring URL entry https://www.dbmeinv.com/ in allowed_domains.
  warnings.warn(message, URLWarning)

2019-06-16 17:34:07 [meinvspider] INFO: Spider opened: meinvspider
2019-06-16 17:34:07 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2019-06-16 17:34:08 [scrapy.core.engine] INFO: Closing spider (finished)
2019-06-16 17:34:08 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 591,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 5121,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2019, 6, 16, 9, 34, 8, 851728),
 'item_scraped_count': 20,
 'log_count/INFO': 11,
 'log_count/WARNING': 1,
 'response_received_count': 2,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/200': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2019, 6, 16, 9, 34, 7, 902730)}
2019-06-16 17:34:08 [scrapy.core.engine] INFO: Spider closed (finished)
2019-06-16 17:35:15 [scrapy.utils.log] INFO: Scrapy 1.6.0 started (bot: dbmeinv)
2019-06-16 17:35:15 [scrapy.utils.log] INFO: Versions: lxml 4.3.4.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.5.1, w3lib 1.20.0, Twisted 18.4.0, Python 3.6.5 (v3.6.5:f59c0932b4, Mar 28 2018, 17:00:18) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 19.0.0 (OpenSSL 1.1.0i  14 Aug 2018), cryptography 2.3.1, Platform Windows-10-10.0.17763-SP0
2019-06-16 17:35:15 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'dbmeinv', 'DOWNLOAD_DELAY': 0.5, 'LOG_FILE': 'log/dbmeinv.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'dbmeinv.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['dbmeinv.spiders']}
2019-06-16 17:35:15 [scrapy.extensions.telnet] INFO: Telnet Password: 305aa30ce7b4b970
2019-06-16 17:35:15 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2019-06-16 17:35:16 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'dbmeinv.rotate_useragent.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'dbmeinv.middlewares.DbmeinvDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-06-16 17:35:16 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'dbmeinv.middlewares.DbmeinvSpiderMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-06-16 17:35:16 [scrapy.middleware] INFO: Enabled item pipelines:
['dbmeinv.pipelines.DbmeinvPipeline']
2019-06-16 17:35:16 [scrapy.core.engine] INFO: Spider opened
2019-06-16 17:35:16 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-06-16 17:35:16 [meinvspider] INFO: Spider opened: meinvspider
2019-06-16 17:35:16 [py.warnings] WARNING: C:\Users\ltf\AppData\Local\Programs\Python\Python36\lib\site-packages\scrapy\spidermiddlewares\offsite.py:61: URLWarning: allowed_domains accepts only domains, not URLs. Ignoring URL entry https://www.dbmeinv.com/ in allowed_domains.
  warnings.warn(message, URLWarning)

2019-06-16 17:35:16 [meinvspider] INFO: Spider opened: meinvspider
2019-06-16 17:35:16 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2019-06-16 17:35:17 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.dbmeinv.com/> (referer: None)
Traceback (most recent call last):
  File "C:\Users\ltf\AppData\Local\Programs\Python\Python36\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\ltf\AppData\Local\Programs\Python\Python36\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "G:\pythonAI\爬虫大全\dbmeinv\dbmeinv\middlewares.py", line 35, in process_spider_output
    for i in result:
  File "C:\Users\ltf\AppData\Local\Programs\Python\Python36\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\ltf\AppData\Local\Programs\Python\Python36\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\ltf\AppData\Local\Programs\Python\Python36\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "G:\pythonAI\爬虫大全\dbmeinv\dbmeinv\spiders\meinvspider.py", line 25, in parse
    nextpageurl=next_page_li.xpath('a/@href').extract_first()
AttributeError: 'NoneType' object has no attribute 'xpath'
2019-06-16 17:35:17 [scrapy.core.engine] INFO: Closing spider (finished)
2019-06-16 17:35:17 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 585,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 5121,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2019, 6, 16, 9, 35, 17, 799726),
 'item_scraped_count': 20,
 'log_count/ERROR': 1,
 'log_count/INFO': 11,
 'log_count/WARNING': 1,
 'response_received_count': 2,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/200': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/AttributeError': 1,
 'start_time': datetime.datetime(2019, 6, 16, 9, 35, 16, 950733)}
2019-06-16 17:35:17 [scrapy.core.engine] INFO: Spider closed (finished)
2019-06-16 17:35:56 [scrapy.utils.log] INFO: Scrapy 1.6.0 started (bot: dbmeinv)
2019-06-16 17:35:56 [scrapy.utils.log] INFO: Versions: lxml 4.3.4.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.5.1, w3lib 1.20.0, Twisted 18.4.0, Python 3.6.5 (v3.6.5:f59c0932b4, Mar 28 2018, 17:00:18) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 19.0.0 (OpenSSL 1.1.0i  14 Aug 2018), cryptography 2.3.1, Platform Windows-10-10.0.17763-SP0
2019-06-16 17:35:56 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'dbmeinv', 'DOWNLOAD_DELAY': 0.5, 'LOG_FILE': 'log/dbmeinv.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'dbmeinv.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['dbmeinv.spiders']}
2019-06-16 17:35:56 [scrapy.extensions.telnet] INFO: Telnet Password: 20b7516d11404e5f
2019-06-16 17:35:56 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2019-06-16 17:35:58 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'dbmeinv.rotate_useragent.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'dbmeinv.middlewares.DbmeinvDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-06-16 17:35:58 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'dbmeinv.middlewares.DbmeinvSpiderMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-06-16 17:35:58 [scrapy.middleware] INFO: Enabled item pipelines:
['dbmeinv.pipelines.DbmeinvPipeline']
2019-06-16 17:35:58 [scrapy.core.engine] INFO: Spider opened
2019-06-16 17:35:58 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-06-16 17:35:58 [meinvspider] INFO: Spider opened: meinvspider
2019-06-16 17:35:58 [py.warnings] WARNING: C:\Users\ltf\AppData\Local\Programs\Python\Python36\lib\site-packages\scrapy\spidermiddlewares\offsite.py:61: URLWarning: allowed_domains accepts only domains, not URLs. Ignoring URL entry https://www.dbmeinv.com/ in allowed_domains.
  warnings.warn(message, URLWarning)

2019-06-16 17:35:58 [meinvspider] INFO: Spider opened: meinvspider
2019-06-16 17:35:58 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2019-06-16 17:35:59 [scrapy.core.engine] INFO: Closing spider (finished)
2019-06-16 17:35:59 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 575,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 5121,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2019, 6, 16, 9, 35, 59, 366730),
 'item_scraped_count': 20,
 'log_count/INFO': 11,
 'log_count/WARNING': 1,
 'response_received_count': 2,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/200': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2019, 6, 16, 9, 35, 58, 573730)}
2019-06-16 17:35:59 [scrapy.core.engine] INFO: Spider closed (finished)
2019-06-16 17:40:53 [scrapy.utils.log] INFO: Scrapy 1.6.0 started (bot: dbmeinv)
2019-06-16 17:40:53 [scrapy.utils.log] INFO: Versions: lxml 4.3.4.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.5.1, w3lib 1.20.0, Twisted 18.4.0, Python 3.6.5 (v3.6.5:f59c0932b4, Mar 28 2018, 17:00:18) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 19.0.0 (OpenSSL 1.1.0i  14 Aug 2018), cryptography 2.3.1, Platform Windows-10-10.0.17763-SP0
2019-06-16 17:40:53 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'dbmeinv', 'DOWNLOAD_DELAY': 0.5, 'LOG_FILE': 'log/dbmeinv.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'dbmeinv.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['dbmeinv.spiders']}
2019-06-16 17:40:53 [scrapy.extensions.telnet] INFO: Telnet Password: fe6f69ef468f2ecf
2019-06-16 17:40:53 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2019-06-16 17:40:55 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'dbmeinv.rotate_useragent.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'dbmeinv.middlewares.DbmeinvDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-06-16 17:40:55 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'dbmeinv.middlewares.DbmeinvSpiderMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-06-16 17:40:55 [scrapy.middleware] INFO: Enabled item pipelines:
['dbmeinv.pipelines.DbmeinvPipeline']
2019-06-16 17:40:55 [scrapy.core.engine] INFO: Spider opened
2019-06-16 17:40:55 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-06-16 17:40:55 [meinvspider] INFO: Spider opened: meinvspider
2019-06-16 17:40:55 [py.warnings] WARNING: C:\Users\ltf\AppData\Local\Programs\Python\Python36\lib\site-packages\scrapy\spidermiddlewares\offsite.py:61: URLWarning: allowed_domains accepts only domains, not URLs. Ignoring URL entry https://www.dbmeinv.com/ in allowed_domains.
  warnings.warn(message, URLWarning)

2019-06-16 17:40:55 [meinvspider] INFO: Spider opened: meinvspider
2019-06-16 17:40:55 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2019-06-16 17:40:56 [scrapy.core.engine] INFO: Closing spider (finished)
2019-06-16 17:40:56 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 571,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 5121,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2019, 6, 16, 9, 40, 56, 661752),
 'item_scraped_count': 20,
 'log_count/INFO': 11,
 'log_count/WARNING': 1,
 'response_received_count': 2,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/200': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2019, 6, 16, 9, 40, 55, 966728)}
2019-06-16 17:40:56 [scrapy.core.engine] INFO: Spider closed (finished)
2019-06-16 17:53:18 [scrapy.utils.log] INFO: Scrapy 1.6.0 started (bot: dbmeinv)
2019-06-16 17:53:18 [scrapy.utils.log] INFO: Versions: lxml 4.3.4.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.5.1, w3lib 1.20.0, Twisted 18.4.0, Python 3.6.5 (v3.6.5:f59c0932b4, Mar 28 2018, 17:00:18) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 19.0.0 (OpenSSL 1.1.0i  14 Aug 2018), cryptography 2.3.1, Platform Windows-10-10.0.17763-SP0
2019-06-16 17:53:18 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'dbmeinv', 'DOWNLOAD_DELAY': 0.5, 'LOG_FILE': 'log/dbmeinv.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'dbmeinv.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['dbmeinv.spiders']}
2019-06-16 17:53:18 [scrapy.extensions.telnet] INFO: Telnet Password: 105a3cfe2e0db38c
2019-06-16 17:53:18 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2019-06-16 17:53:21 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'dbmeinv.rotate_useragent.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'dbmeinv.middlewares.DbmeinvDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-06-16 17:53:21 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'dbmeinv.middlewares.DbmeinvSpiderMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-06-16 17:53:21 [scrapy.middleware] INFO: Enabled item pipelines:
['dbmeinv.pipelines.DbmeinvPipeline']
2019-06-16 17:53:21 [scrapy.core.engine] INFO: Spider opened
2019-06-16 17:53:21 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-06-16 17:53:21 [meinvspider] INFO: Spider opened: meinvspider
2019-06-16 17:53:21 [py.warnings] WARNING: C:\Users\ltf\AppData\Local\Programs\Python\Python36\lib\site-packages\scrapy\spidermiddlewares\offsite.py:61: URLWarning: allowed_domains accepts only domains, not URLs. Ignoring URL entry https://www.dbmeinv.com/ in allowed_domains.
  warnings.warn(message, URLWarning)

2019-06-16 17:53:21 [meinvspider] INFO: Spider opened: meinvspider
2019-06-16 17:53:21 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2019-06-16 17:53:21 [scrapy.core.engine] INFO: Closing spider (finished)
2019-06-16 17:53:21 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 573,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 5121,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2019, 6, 16, 9, 53, 21, 969890),
 'item_scraped_count': 20,
 'log_count/INFO': 11,
 'log_count/WARNING': 1,
 'response_received_count': 2,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/200': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2019, 6, 16, 9, 53, 21, 48200)}
2019-06-16 17:53:21 [scrapy.core.engine] INFO: Spider closed (finished)
2019-06-16 17:53:27 [scrapy.utils.log] INFO: Scrapy 1.6.0 started (bot: dbmeinv)
2019-06-16 17:53:27 [scrapy.utils.log] INFO: Versions: lxml 4.3.4.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.5.1, w3lib 1.20.0, Twisted 18.4.0, Python 3.6.5 (v3.6.5:f59c0932b4, Mar 28 2018, 17:00:18) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 19.0.0 (OpenSSL 1.1.0i  14 Aug 2018), cryptography 2.3.1, Platform Windows-10-10.0.17763-SP0
2019-06-16 17:53:27 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'dbmeinv', 'DOWNLOAD_DELAY': 0.5, 'LOG_FILE': 'log/dbmeinv.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'dbmeinv.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['dbmeinv.spiders']}
2019-06-16 17:53:27 [scrapy.extensions.telnet] INFO: Telnet Password: 14db95108c14b2d3
2019-06-16 17:53:27 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2019-06-16 17:53:29 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'dbmeinv.rotate_useragent.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'dbmeinv.middlewares.DbmeinvDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-06-16 17:53:29 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'dbmeinv.middlewares.DbmeinvSpiderMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-06-16 17:53:29 [scrapy.middleware] INFO: Enabled item pipelines:
['dbmeinv.pipelines.DbmeinvPipeline']
2019-06-16 17:53:29 [scrapy.core.engine] INFO: Spider opened
2019-06-16 17:53:30 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-06-16 17:53:30 [meinvspider] INFO: Spider opened: meinvspider
2019-06-16 17:53:30 [py.warnings] WARNING: C:\Users\ltf\AppData\Local\Programs\Python\Python36\lib\site-packages\scrapy\spidermiddlewares\offsite.py:61: URLWarning: allowed_domains accepts only domains, not URLs. Ignoring URL entry https://www.dbmeinv.com/ in allowed_domains.
  warnings.warn(message, URLWarning)

2019-06-16 17:53:30 [meinvspider] INFO: Spider opened: meinvspider
2019-06-16 17:53:30 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2019-06-16 17:53:31 [scrapy.core.engine] INFO: Closing spider (finished)
2019-06-16 17:53:31 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 579,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 5121,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2019, 6, 16, 9, 53, 31, 7885),
 'item_scraped_count': 20,
 'log_count/INFO': 11,
 'log_count/WARNING': 1,
 'response_received_count': 2,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/200': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2019, 6, 16, 9, 53, 30, 19883)}
2019-06-16 17:53:31 [scrapy.core.engine] INFO: Spider closed (finished)
2019-06-16 17:54:29 [scrapy.utils.log] INFO: Scrapy 1.6.0 started (bot: dbmeinv)
2019-06-16 17:54:29 [scrapy.utils.log] INFO: Versions: lxml 4.3.4.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.5.1, w3lib 1.20.0, Twisted 18.4.0, Python 3.6.5 (v3.6.5:f59c0932b4, Mar 28 2018, 17:00:18) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 19.0.0 (OpenSSL 1.1.0i  14 Aug 2018), cryptography 2.3.1, Platform Windows-10-10.0.17763-SP0
2019-06-16 17:54:29 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'dbmeinv', 'DOWNLOAD_DELAY': 0.5, 'LOG_FILE': 'log/dbmeinv.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'dbmeinv.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['dbmeinv.spiders']}
2019-06-16 17:54:29 [scrapy.extensions.telnet] INFO: Telnet Password: b9c5bbb99fb53418
2019-06-16 17:54:30 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2019-06-16 17:54:31 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'dbmeinv.rotate_useragent.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'dbmeinv.middlewares.DbmeinvDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-06-16 17:54:31 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'dbmeinv.middlewares.DbmeinvSpiderMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-06-16 17:54:31 [scrapy.middleware] INFO: Enabled item pipelines:
['dbmeinv.pipelines.DbmeinvPipeline']
2019-06-16 17:54:31 [scrapy.core.engine] INFO: Spider opened
2019-06-16 17:54:31 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-06-16 17:54:31 [meinvspider] INFO: Spider opened: meinvspider
2019-06-16 17:54:31 [py.warnings] WARNING: C:\Users\ltf\AppData\Local\Programs\Python\Python36\lib\site-packages\scrapy\spidermiddlewares\offsite.py:61: URLWarning: allowed_domains accepts only domains, not URLs. Ignoring URL entry https://www.dbmeinv.com/ in allowed_domains.
  warnings.warn(message, URLWarning)

2019-06-16 17:54:31 [meinvspider] INFO: Spider opened: meinvspider
2019-06-16 17:54:31 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2019-06-16 17:54:33 [scrapy.core.engine] INFO: Closing spider (finished)
2019-06-16 17:54:33 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 692,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 5121,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2019, 6, 16, 9, 54, 33, 96887),
 'item_scraped_count': 20,
 'log_count/INFO': 11,
 'log_count/WARNING': 1,
 'response_received_count': 2,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/200': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2019, 6, 16, 9, 54, 31, 928884)}
2019-06-16 17:54:33 [scrapy.core.engine] INFO: Spider closed (finished)
2019-06-16 17:54:47 [scrapy.utils.log] INFO: Scrapy 1.6.0 started (bot: dbmeinv)
2019-06-16 17:54:47 [scrapy.utils.log] INFO: Versions: lxml 4.3.4.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.5.1, w3lib 1.20.0, Twisted 18.4.0, Python 3.6.5 (v3.6.5:f59c0932b4, Mar 28 2018, 17:00:18) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 19.0.0 (OpenSSL 1.1.0i  14 Aug 2018), cryptography 2.3.1, Platform Windows-10-10.0.17763-SP0
2019-06-16 17:54:47 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'dbmeinv', 'DOWNLOAD_DELAY': 0.5, 'LOG_FILE': 'log/dbmeinv.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'dbmeinv.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['dbmeinv.spiders']}
2019-06-16 17:54:47 [scrapy.extensions.telnet] INFO: Telnet Password: 8b93bdc046fdc360
2019-06-16 17:54:47 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2019-06-16 17:54:49 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'dbmeinv.rotate_useragent.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'dbmeinv.middlewares.DbmeinvDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-06-16 17:54:49 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'dbmeinv.middlewares.DbmeinvSpiderMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-06-16 17:54:49 [scrapy.middleware] INFO: Enabled item pipelines:
['dbmeinv.pipelines.DbmeinvPipeline']
2019-06-16 17:54:49 [scrapy.core.engine] INFO: Spider opened
2019-06-16 17:54:49 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-06-16 17:54:49 [meinvspider] INFO: Spider opened: meinvspider
2019-06-16 17:54:49 [py.warnings] WARNING: C:\Users\ltf\AppData\Local\Programs\Python\Python36\lib\site-packages\scrapy\spidermiddlewares\offsite.py:61: URLWarning: allowed_domains accepts only domains, not URLs. Ignoring URL entry https://www.dbmeinv.com/ in allowed_domains.
  warnings.warn(message, URLWarning)

2019-06-16 17:54:49 [meinvspider] INFO: Spider opened: meinvspider
2019-06-16 17:54:49 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2019-06-16 17:54:50 [scrapy.core.engine] INFO: Closing spider (finished)
2019-06-16 17:54:50 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 573,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 5121,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2019, 6, 16, 9, 54, 50, 348881),
 'item_scraped_count': 20,
 'log_count/INFO': 11,
 'log_count/WARNING': 1,
 'response_received_count': 2,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/200': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2019, 6, 16, 9, 54, 49, 429879)}
2019-06-16 17:54:50 [scrapy.core.engine] INFO: Spider closed (finished)
2019-06-16 17:57:17 [scrapy.utils.log] INFO: Scrapy 1.6.0 started (bot: dbmeinv)
2019-06-16 17:57:17 [scrapy.utils.log] INFO: Versions: lxml 4.3.4.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.5.1, w3lib 1.20.0, Twisted 18.4.0, Python 3.6.5 (v3.6.5:f59c0932b4, Mar 28 2018, 17:00:18) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 19.0.0 (OpenSSL 1.1.0i  14 Aug 2018), cryptography 2.3.1, Platform Windows-10-10.0.17763-SP0
2019-06-16 17:57:17 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'dbmeinv', 'DOWNLOAD_DELAY': 0.5, 'LOG_FILE': 'log/dbmeinv.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'dbmeinv.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['dbmeinv.spiders']}
2019-06-16 17:57:17 [scrapy.extensions.telnet] INFO: Telnet Password: d1b09496067bd5a0
2019-06-16 17:57:18 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2019-06-16 17:57:21 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'dbmeinv.rotate_useragent.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'dbmeinv.middlewares.DbmeinvDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-06-16 17:57:21 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'dbmeinv.middlewares.DbmeinvSpiderMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-06-16 17:57:21 [scrapy.middleware] INFO: Enabled item pipelines:
['dbmeinv.pipelines.DbmeinvPipeline']
2019-06-16 17:57:21 [scrapy.core.engine] INFO: Spider opened
2019-06-16 17:57:21 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-06-16 17:57:21 [meinvspider] INFO: Spider opened: meinvspider
2019-06-16 17:57:21 [py.warnings] WARNING: C:\Users\ltf\AppData\Local\Programs\Python\Python36\lib\site-packages\scrapy\spidermiddlewares\offsite.py:61: URLWarning: allowed_domains accepts only domains, not URLs. Ignoring URL entry https://www.dbmeinv.com/ in allowed_domains.
  warnings.warn(message, URLWarning)

2019-06-16 17:57:21 [meinvspider] INFO: Spider opened: meinvspider
2019-06-16 17:57:21 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2019-06-16 17:57:22 [scrapy.core.engine] INFO: Closing spider (finished)
2019-06-16 17:57:22 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 573,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 5121,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2019, 6, 16, 9, 57, 22, 262488),
 'item_scraped_count': 20,
 'log_count/INFO': 11,
 'log_count/WARNING': 1,
 'response_received_count': 2,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/200': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2019, 6, 16, 9, 57, 21, 371481)}
2019-06-16 17:57:22 [scrapy.core.engine] INFO: Spider closed (finished)
2019-06-16 17:58:46 [scrapy.utils.log] INFO: Scrapy 1.6.0 started (bot: dbmeinv)
2019-06-16 17:58:46 [scrapy.utils.log] INFO: Versions: lxml 4.3.4.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.5.1, w3lib 1.20.0, Twisted 18.4.0, Python 3.6.5 (v3.6.5:f59c0932b4, Mar 28 2018, 17:00:18) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 19.0.0 (OpenSSL 1.1.0i  14 Aug 2018), cryptography 2.3.1, Platform Windows-10-10.0.17763-SP0
2019-06-16 17:58:46 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'dbmeinv', 'DOWNLOAD_DELAY': 0.5, 'LOG_FILE': 'log/dbmeinv.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'dbmeinv.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['dbmeinv.spiders']}
2019-06-16 17:58:46 [scrapy.extensions.telnet] INFO: Telnet Password: bb51da150c886c59
2019-06-16 17:58:46 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2019-06-16 17:58:48 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'dbmeinv.rotate_useragent.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'dbmeinv.middlewares.DbmeinvDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-06-16 17:58:48 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'dbmeinv.middlewares.DbmeinvSpiderMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-06-16 17:58:48 [scrapy.middleware] INFO: Enabled item pipelines:
['dbmeinv.pipelines.DbmeinvPipeline']
2019-06-16 17:58:48 [scrapy.core.engine] INFO: Spider opened
2019-06-16 17:58:48 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-06-16 17:58:48 [meinvspider] INFO: Spider opened: meinvspider
2019-06-16 17:58:48 [py.warnings] WARNING: C:\Users\ltf\AppData\Local\Programs\Python\Python36\lib\site-packages\scrapy\spidermiddlewares\offsite.py:61: URLWarning: allowed_domains accepts only domains, not URLs. Ignoring URL entry https://www.dbmeinv.com/ in allowed_domains.
  warnings.warn(message, URLWarning)

2019-06-16 17:58:48 [meinvspider] INFO: Spider opened: meinvspider
2019-06-16 17:58:48 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2019-06-16 17:58:49 [scrapy.core.engine] INFO: Closing spider (finished)
2019-06-16 17:58:49 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 572,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 5121,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2019, 6, 16, 9, 58, 49, 466490),
 'item_scraped_count': 20,
 'log_count/INFO': 11,
 'log_count/WARNING': 1,
 'offsite/domains': 1,
 'offsite/filtered': 1,
 'request_depth_max': 1,
 'response_received_count': 2,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/200': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2019, 6, 16, 9, 58, 48, 942487)}
2019-06-16 17:58:49 [scrapy.core.engine] INFO: Spider closed (finished)
2019-06-16 18:01:39 [scrapy.utils.log] INFO: Scrapy 1.6.0 started (bot: dbmeinv)
2019-06-16 18:01:39 [scrapy.utils.log] INFO: Versions: lxml 4.3.4.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.5.1, w3lib 1.20.0, Twisted 18.4.0, Python 3.6.5 (v3.6.5:f59c0932b4, Mar 28 2018, 17:00:18) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 19.0.0 (OpenSSL 1.1.0i  14 Aug 2018), cryptography 2.3.1, Platform Windows-10-10.0.17763-SP0
2019-06-16 18:01:39 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'dbmeinv', 'DOWNLOAD_DELAY': 0.5, 'LOG_FILE': 'log/dbmeinv.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'dbmeinv.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['dbmeinv.spiders']}
2019-06-16 18:01:39 [scrapy.extensions.telnet] INFO: Telnet Password: 23e2e4041e6899af
2019-06-16 18:01:39 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2019-06-16 18:01:41 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'dbmeinv.rotate_useragent.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'dbmeinv.middlewares.DbmeinvDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-06-16 18:01:41 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'dbmeinv.middlewares.DbmeinvSpiderMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-06-16 18:01:41 [scrapy.middleware] INFO: Enabled item pipelines:
['dbmeinv.pipelines.DbmeinvPipeline']
2019-06-16 18:01:41 [scrapy.core.engine] INFO: Spider opened
2019-06-16 18:01:41 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-06-16 18:01:41 [meinvspider] INFO: Spider opened: meinvspider
2019-06-16 18:01:41 [py.warnings] WARNING: C:\Users\ltf\AppData\Local\Programs\Python\Python36\lib\site-packages\scrapy\spidermiddlewares\offsite.py:61: URLWarning: allowed_domains accepts only domains, not URLs. Ignoring URL entry https://www.dbmeinv.com/ in allowed_domains.
  warnings.warn(message, URLWarning)

2019-06-16 18:01:41 [meinvspider] INFO: Spider opened: meinvspider
2019-06-16 18:01:41 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2019-06-16 18:12:07 [scrapy.utils.log] INFO: Scrapy 1.6.0 started (bot: dbmeinv)
2019-06-16 18:12:07 [scrapy.utils.log] INFO: Versions: lxml 4.3.4.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.5.1, w3lib 1.20.0, Twisted 18.4.0, Python 3.6.5 (v3.6.5:f59c0932b4, Mar 28 2018, 17:00:18) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 19.0.0 (OpenSSL 1.1.0i  14 Aug 2018), cryptography 2.3.1, Platform Windows-10-10.0.17763-SP0
2019-06-16 18:12:08 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'dbmeinv', 'DOWNLOAD_DELAY': 0.5, 'LOG_FILE': 'log/dbmeinv.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'dbmeinv.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['dbmeinv.spiders']}
2019-06-16 18:12:08 [scrapy.extensions.telnet] INFO: Telnet Password: 57155cd1fac62f00
2019-06-16 18:12:08 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2019-06-16 18:12:10 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'dbmeinv.rotate_useragent.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'dbmeinv.middlewares.DbmeinvDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-06-16 18:12:10 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'dbmeinv.middlewares.DbmeinvSpiderMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-06-16 18:12:10 [twisted] CRITICAL: Unhandled error in Deferred:
2019-06-16 18:12:10 [twisted] CRITICAL: 
Traceback (most recent call last):
  File "C:\Users\ltf\AppData\Local\Programs\Python\Python36\lib\site-packages\twisted\internet\defer.py", line 1386, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\ltf\AppData\Local\Programs\Python\Python36\lib\site-packages\scrapy\crawler.py", line 80, in crawl
    self.engine = self._create_engine()
  File "C:\Users\ltf\AppData\Local\Programs\Python\Python36\lib\site-packages\scrapy\crawler.py", line 105, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "C:\Users\ltf\AppData\Local\Programs\Python\Python36\lib\site-packages\scrapy\core\engine.py", line 70, in __init__
    self.scraper = Scraper(crawler)
  File "C:\Users\ltf\AppData\Local\Programs\Python\Python36\lib\site-packages\scrapy\core\scraper.py", line 71, in __init__
    self.itemproc = itemproc_cls.from_crawler(crawler)
  File "C:\Users\ltf\AppData\Local\Programs\Python\Python36\lib\site-packages\scrapy\middleware.py", line 53, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "C:\Users\ltf\AppData\Local\Programs\Python\Python36\lib\site-packages\scrapy\middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "C:\Users\ltf\AppData\Local\Programs\Python\Python36\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Users\ltf\AppData\Local\Programs\Python\Python36\lib\importlib\__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 994, in _gcd_import
  File "<frozen importlib._bootstrap>", line 971, in _find_and_load
  File "<frozen importlib._bootstrap>", line 953, in _find_and_load_unlocked
ModuleNotFoundError: No module named 'dbmeinv.iopipelines'
2019-06-16 18:13:01 [scrapy.utils.log] INFO: Scrapy 1.6.0 started (bot: dbmeinv)
2019-06-16 18:13:01 [scrapy.utils.log] INFO: Versions: lxml 4.3.4.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.5.1, w3lib 1.20.0, Twisted 18.4.0, Python 3.6.5 (v3.6.5:f59c0932b4, Mar 28 2018, 17:00:18) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 19.0.0 (OpenSSL 1.1.0i  14 Aug 2018), cryptography 2.3.1, Platform Windows-10-10.0.17763-SP0
2019-06-16 18:13:01 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'dbmeinv', 'DOWNLOAD_DELAY': 0.5, 'LOG_FILE': 'log/dbmeinv.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'dbmeinv.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['dbmeinv.spiders']}
2019-06-16 18:13:01 [scrapy.extensions.telnet] INFO: Telnet Password: e0f596f76b98d558
2019-06-16 18:13:01 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2019-06-16 18:13:03 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'dbmeinv.rotate_useragent.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'dbmeinv.middlewares.DbmeinvDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-06-16 18:13:03 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'dbmeinv.middlewares.DbmeinvSpiderMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-06-16 18:13:03 [twisted] CRITICAL: Unhandled error in Deferred:
2019-06-16 18:13:03 [twisted] CRITICAL: 
Traceback (most recent call last):
  File "C:\Users\ltf\AppData\Local\Programs\Python\Python36\lib\site-packages\twisted\internet\defer.py", line 1386, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\ltf\AppData\Local\Programs\Python\Python36\lib\site-packages\scrapy\crawler.py", line 80, in crawl
    self.engine = self._create_engine()
  File "C:\Users\ltf\AppData\Local\Programs\Python\Python36\lib\site-packages\scrapy\crawler.py", line 105, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "C:\Users\ltf\AppData\Local\Programs\Python\Python36\lib\site-packages\scrapy\core\engine.py", line 70, in __init__
    self.scraper = Scraper(crawler)
  File "C:\Users\ltf\AppData\Local\Programs\Python\Python36\lib\site-packages\scrapy\core\scraper.py", line 71, in __init__
    self.itemproc = itemproc_cls.from_crawler(crawler)
  File "C:\Users\ltf\AppData\Local\Programs\Python\Python36\lib\site-packages\scrapy\middleware.py", line 53, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "C:\Users\ltf\AppData\Local\Programs\Python\Python36\lib\site-packages\scrapy\middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "C:\Users\ltf\AppData\Local\Programs\Python\Python36\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Users\ltf\AppData\Local\Programs\Python\Python36\lib\importlib\__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 994, in _gcd_import
  File "<frozen importlib._bootstrap>", line 971, in _find_and_load
  File "<frozen importlib._bootstrap>", line 953, in _find_and_load_unlocked
ModuleNotFoundError: No module named 'dbmeinv.iopipelines'
2019-06-16 18:13:26 [scrapy.utils.log] INFO: Scrapy 1.6.0 started (bot: dbmeinv)
2019-06-16 18:13:26 [scrapy.utils.log] INFO: Versions: lxml 4.3.4.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.5.1, w3lib 1.20.0, Twisted 18.4.0, Python 3.6.5 (v3.6.5:f59c0932b4, Mar 28 2018, 17:00:18) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 19.0.0 (OpenSSL 1.1.0i  14 Aug 2018), cryptography 2.3.1, Platform Windows-10-10.0.17763-SP0
2019-06-16 18:13:26 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'dbmeinv', 'DOWNLOAD_DELAY': 0.5, 'LOG_FILE': 'log/dbmeinv.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'dbmeinv.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['dbmeinv.spiders']}
2019-06-16 18:13:26 [scrapy.extensions.telnet] INFO: Telnet Password: c67474ed57bfea35
2019-06-16 18:13:26 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2019-06-16 18:13:28 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'dbmeinv.rotate_useragent.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'dbmeinv.middlewares.DbmeinvDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-06-16 18:13:28 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'dbmeinv.middlewares.DbmeinvSpiderMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-06-16 18:13:28 [scrapy.middleware] INFO: Enabled item pipelines:
['dbmeinv.pipelines.DbmeinvPipeline']
2019-06-16 18:13:28 [scrapy.core.engine] INFO: Spider opened
2019-06-16 18:13:28 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-06-16 18:13:28 [meinvspider] INFO: Spider opened: meinvspider
2019-06-16 18:13:28 [py.warnings] WARNING: C:\Users\ltf\AppData\Local\Programs\Python\Python36\lib\site-packages\scrapy\spidermiddlewares\offsite.py:61: URLWarning: allowed_domains accepts only domains, not URLs. Ignoring URL entry https://www.dbmeinv.com/ in allowed_domains.
  warnings.warn(message, URLWarning)

2019-06-16 18:13:28 [meinvspider] INFO: Spider opened: meinvspider
2019-06-16 18:13:28 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2019-06-16 18:17:09 [scrapy.utils.log] INFO: Scrapy 1.6.0 started (bot: dbmeinv)
2019-06-16 18:17:09 [scrapy.utils.log] INFO: Versions: lxml 4.3.4.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.5.1, w3lib 1.20.0, Twisted 18.4.0, Python 3.6.5 (v3.6.5:f59c0932b4, Mar 28 2018, 17:00:18) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 19.0.0 (OpenSSL 1.1.0i  14 Aug 2018), cryptography 2.3.1, Platform Windows-10-10.0.17763-SP0
2019-06-16 18:17:09 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'dbmeinv', 'DOWNLOAD_DELAY': 0.5, 'LOG_FILE': 'log/dbmeinv.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'dbmeinv.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['dbmeinv.spiders']}
2019-06-16 18:17:09 [scrapy.extensions.telnet] INFO: Telnet Password: 1a4eaa9cfb8b880e
2019-06-16 18:17:09 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2019-06-16 18:17:11 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'dbmeinv.rotate_useragent.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'dbmeinv.middlewares.DbmeinvDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-06-16 18:17:11 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'dbmeinv.middlewares.DbmeinvSpiderMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-06-16 18:17:11 [twisted] CRITICAL: Unhandled error in Deferred:
2019-06-16 18:17:11 [twisted] CRITICAL: 
Traceback (most recent call last):
  File "C:\Users\ltf\AppData\Local\Programs\Python\Python36\lib\site-packages\twisted\internet\defer.py", line 1386, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\ltf\AppData\Local\Programs\Python\Python36\lib\site-packages\scrapy\crawler.py", line 80, in crawl
    self.engine = self._create_engine()
  File "C:\Users\ltf\AppData\Local\Programs\Python\Python36\lib\site-packages\scrapy\crawler.py", line 105, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "C:\Users\ltf\AppData\Local\Programs\Python\Python36\lib\site-packages\scrapy\core\engine.py", line 70, in __init__
    self.scraper = Scraper(crawler)
  File "C:\Users\ltf\AppData\Local\Programs\Python\Python36\lib\site-packages\scrapy\core\scraper.py", line 71, in __init__
    self.itemproc = itemproc_cls.from_crawler(crawler)
  File "C:\Users\ltf\AppData\Local\Programs\Python\Python36\lib\site-packages\scrapy\middleware.py", line 53, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "C:\Users\ltf\AppData\Local\Programs\Python\Python36\lib\site-packages\scrapy\middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "C:\Users\ltf\AppData\Local\Programs\Python\Python36\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Users\ltf\AppData\Local\Programs\Python\Python36\lib\importlib\__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 994, in _gcd_import
  File "<frozen importlib._bootstrap>", line 971, in _find_and_load
  File "<frozen importlib._bootstrap>", line 953, in _find_and_load_unlocked
ModuleNotFoundError: No module named 'dbmeinv.iopipelines'
2019-06-16 18:25:03 [scrapy.utils.log] INFO: Scrapy 1.6.0 started (bot: dbmeinv)
2019-06-16 18:25:03 [scrapy.utils.log] INFO: Versions: lxml 4.3.4.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.5.1, w3lib 1.20.0, Twisted 18.4.0, Python 3.6.5 (v3.6.5:f59c0932b4, Mar 28 2018, 17:00:18) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 19.0.0 (OpenSSL 1.1.0i  14 Aug 2018), cryptography 2.3.1, Platform Windows-10-10.0.17763-SP0
2019-06-16 18:25:03 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'dbmeinv', 'DOWNLOAD_DELAY': 0.5, 'LOG_FILE': 'log/dbmeinv.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'dbmeinv.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['dbmeinv.spiders']}
2019-06-16 18:25:03 [scrapy.extensions.telnet] INFO: Telnet Password: ad3e0af2d49c6976
2019-06-16 18:25:03 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2019-06-16 18:25:06 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'dbmeinv.rotate_useragent.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'dbmeinv.middlewares.DbmeinvDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-06-16 18:25:06 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'dbmeinv.middlewares.DbmeinvSpiderMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-06-16 18:25:06 [scrapy.middleware] INFO: Enabled item pipelines:
['dbmeinv.iopipeline.DbmeinvIoPipeline']
2019-06-16 18:25:06 [scrapy.core.engine] INFO: Spider opened
2019-06-16 18:25:06 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-06-16 18:25:06 [meinvspider] INFO: Spider opened: meinvspider
2019-06-16 18:25:06 [py.warnings] WARNING: C:\Users\ltf\AppData\Local\Programs\Python\Python36\lib\site-packages\scrapy\spidermiddlewares\offsite.py:61: URLWarning: allowed_domains accepts only domains, not URLs. Ignoring URL entry https://www.dbmeinv.com/ in allowed_domains.
  warnings.warn(message, URLWarning)

2019-06-16 18:25:06 [meinvspider] INFO: Spider opened: meinvspider
2019-06-16 18:25:06 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2019-06-16 18:30:17 [scrapy.utils.log] INFO: Scrapy 1.6.0 started (bot: dbmeinv)
2019-06-16 18:30:17 [scrapy.utils.log] INFO: Versions: lxml 4.3.4.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.5.1, w3lib 1.20.0, Twisted 18.4.0, Python 3.6.5 (v3.6.5:f59c0932b4, Mar 28 2018, 17:00:18) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 19.0.0 (OpenSSL 1.1.0i  14 Aug 2018), cryptography 2.3.1, Platform Windows-10-10.0.17763-SP0
2019-06-16 18:30:17 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'dbmeinv', 'DOWNLOAD_DELAY': 0.5, 'LOG_FILE': 'log/dbmeinv.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'dbmeinv.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['dbmeinv.spiders']}
2019-06-16 18:30:17 [scrapy.extensions.telnet] INFO: Telnet Password: aa8f4f5b874baddd
2019-06-16 18:30:17 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2019-06-16 18:30:19 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'dbmeinv.rotate_useragent.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'dbmeinv.middlewares.DbmeinvDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-06-16 18:30:19 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'dbmeinv.middlewares.DbmeinvSpiderMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-06-16 18:30:20 [scrapy.middleware] INFO: Enabled item pipelines:
['dbmeinv.pipelines.DbmeinvPipeline', 'dbmeinv.iopipeline.DbmeinvIoPipeline']
2019-06-16 18:30:20 [scrapy.core.engine] INFO: Spider opened
2019-06-16 18:30:20 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-06-16 18:30:20 [meinvspider] INFO: Spider opened: meinvspider
2019-06-16 18:30:20 [py.warnings] WARNING: C:\Users\ltf\AppData\Local\Programs\Python\Python36\lib\site-packages\scrapy\spidermiddlewares\offsite.py:61: URLWarning: allowed_domains accepts only domains, not URLs. Ignoring URL entry https://www.dbmeinv.com/ in allowed_domains.
  warnings.warn(message, URLWarning)

2019-06-16 18:30:20 [meinvspider] INFO: Spider opened: meinvspider
2019-06-16 18:30:20 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2019-06-16 18:31:59 [scrapy.utils.log] INFO: Scrapy 1.6.0 started (bot: dbmeinv)
2019-06-16 18:31:59 [scrapy.utils.log] INFO: Versions: lxml 4.3.4.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.5.1, w3lib 1.20.0, Twisted 18.4.0, Python 3.6.5 (v3.6.5:f59c0932b4, Mar 28 2018, 17:00:18) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 19.0.0 (OpenSSL 1.1.0i  14 Aug 2018), cryptography 2.3.1, Platform Windows-10-10.0.17763-SP0
2019-06-16 18:31:59 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'dbmeinv', 'DOWNLOAD_DELAY': 0.5, 'LOG_FILE': 'log/dbmeinv.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'dbmeinv.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['dbmeinv.spiders']}
2019-06-16 18:31:59 [scrapy.extensions.telnet] INFO: Telnet Password: b32fd70663960518
2019-06-16 18:31:59 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2019-06-16 18:32:01 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'dbmeinv.rotate_useragent.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'dbmeinv.middlewares.DbmeinvDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-06-16 18:32:01 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'dbmeinv.middlewares.DbmeinvSpiderMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-06-16 18:32:01 [scrapy.middleware] INFO: Enabled item pipelines:
['dbmeinv.iopipeline.DbmeinvIoPipeline']
2019-06-16 18:32:01 [scrapy.core.engine] INFO: Spider opened
2019-06-16 18:32:01 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-06-16 18:32:01 [meinvspider] INFO: Spider opened: meinvspider
2019-06-16 18:32:01 [py.warnings] WARNING: C:\Users\ltf\AppData\Local\Programs\Python\Python36\lib\site-packages\scrapy\spidermiddlewares\offsite.py:61: URLWarning: allowed_domains accepts only domains, not URLs. Ignoring URL entry https://www.dbmeinv.com/ in allowed_domains.
  warnings.warn(message, URLWarning)

2019-06-16 18:32:01 [meinvspider] INFO: Spider opened: meinvspider
2019-06-16 18:32:01 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2019-06-16 18:35:56 [scrapy.utils.log] INFO: Scrapy 1.6.0 started (bot: dbmeinv)
2019-06-16 18:35:56 [scrapy.utils.log] INFO: Versions: lxml 4.3.4.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.5.1, w3lib 1.20.0, Twisted 18.4.0, Python 3.6.5 (v3.6.5:f59c0932b4, Mar 28 2018, 17:00:18) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 19.0.0 (OpenSSL 1.1.0i  14 Aug 2018), cryptography 2.3.1, Platform Windows-10-10.0.17763-SP0
2019-06-16 18:35:56 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'dbmeinv', 'DOWNLOAD_DELAY': 0.5, 'LOG_FILE': 'log/dbmeinv.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'dbmeinv.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['dbmeinv.spiders']}
2019-06-16 18:35:56 [scrapy.extensions.telnet] INFO: Telnet Password: fb2370edd46ab834
2019-06-16 18:35:56 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2019-06-16 18:35:58 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'dbmeinv.rotate_useragent.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'dbmeinv.middlewares.DbmeinvDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-06-16 18:35:58 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'dbmeinv.middlewares.DbmeinvSpiderMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-06-16 18:35:58 [scrapy.middleware] INFO: Enabled item pipelines:
['dbmeinv.iopipeline.DbmeinvIoPipeline']
2019-06-16 18:35:58 [scrapy.core.engine] INFO: Spider opened
2019-06-16 18:35:58 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-06-16 18:35:58 [meinvspider] INFO: Spider opened: meinvspider
2019-06-16 18:35:58 [py.warnings] WARNING: C:\Users\ltf\AppData\Local\Programs\Python\Python36\lib\site-packages\scrapy\spidermiddlewares\offsite.py:61: URLWarning: allowed_domains accepts only domains, not URLs. Ignoring URL entry https://www.dbmeinv.com/ in allowed_domains.
  warnings.warn(message, URLWarning)

2019-06-16 18:35:58 [meinvspider] INFO: Spider opened: meinvspider
2019-06-16 18:35:58 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2019-06-16 18:36:21 [scrapy.utils.log] INFO: Scrapy 1.6.0 started (bot: dbmeinv)
2019-06-16 18:36:21 [scrapy.utils.log] INFO: Versions: lxml 4.3.4.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.5.1, w3lib 1.20.0, Twisted 18.4.0, Python 3.6.5 (v3.6.5:f59c0932b4, Mar 28 2018, 17:00:18) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 19.0.0 (OpenSSL 1.1.0i  14 Aug 2018), cryptography 2.3.1, Platform Windows-10-10.0.17763-SP0
2019-06-16 18:36:21 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'dbmeinv', 'DOWNLOAD_DELAY': 0.5, 'LOG_FILE': 'log/dbmeinv.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'dbmeinv.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['dbmeinv.spiders']}
2019-06-16 18:36:21 [scrapy.extensions.telnet] INFO: Telnet Password: e4e6f362ffdec871
2019-06-16 18:36:21 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2019-06-16 18:36:23 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'dbmeinv.rotate_useragent.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'dbmeinv.middlewares.DbmeinvDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-06-16 18:36:23 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'dbmeinv.middlewares.DbmeinvSpiderMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-06-16 18:36:23 [scrapy.middleware] INFO: Enabled item pipelines:
['dbmeinv.iopipeline.DbmeinvIoPipeline']
2019-06-16 18:36:23 [scrapy.core.engine] INFO: Spider opened
2019-06-16 18:36:23 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-06-16 18:36:23 [meinvspider] INFO: Spider opened: meinvspider
2019-06-16 18:36:23 [py.warnings] WARNING: C:\Users\ltf\AppData\Local\Programs\Python\Python36\lib\site-packages\scrapy\spidermiddlewares\offsite.py:61: URLWarning: allowed_domains accepts only domains, not URLs. Ignoring URL entry https://www.dbmeinv.com/ in allowed_domains.
  warnings.warn(message, URLWarning)

2019-06-16 18:36:23 [meinvspider] INFO: Spider opened: meinvspider
2019-06-16 18:36:23 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2019-06-16 18:37:23 [scrapy.extensions.logstats] INFO: Crawled 13 pages (at 13 pages/min), scraped 235 items (at 235 items/min)
2019-06-16 18:38:24 [scrapy.extensions.logstats] INFO: Crawled 22 pages (at 9 pages/min), scraped 415 items (at 180 items/min)
2019-06-16 18:39:23 [scrapy.extensions.logstats] INFO: Crawled 31 pages (at 9 pages/min), scraped 592 items (at 177 items/min)
2019-06-16 18:40:23 [scrapy.extensions.logstats] INFO: Crawled 39 pages (at 8 pages/min), scraped 752 items (at 160 items/min)
2019-06-16 18:41:23 [scrapy.extensions.logstats] INFO: Crawled 46 pages (at 7 pages/min), scraped 887 items (at 135 items/min)
2019-06-16 18:42:23 [scrapy.extensions.logstats] INFO: Crawled 53 pages (at 7 pages/min), scraped 1036 items (at 149 items/min)
2019-06-16 18:43:23 [scrapy.extensions.logstats] INFO: Crawled 60 pages (at 7 pages/min), scraped 1180 items (at 144 items/min)
2019-06-16 18:44:23 [scrapy.extensions.logstats] INFO: Crawled 68 pages (at 8 pages/min), scraped 1340 items (at 160 items/min)
2019-06-16 18:45:23 [scrapy.extensions.logstats] INFO: Crawled 75 pages (at 7 pages/min), scraped 1477 items (at 137 items/min)
2019-06-16 18:46:23 [scrapy.extensions.logstats] INFO: Crawled 81 pages (at 6 pages/min), scraped 1592 items (at 115 items/min)
2019-06-16 18:47:23 [scrapy.extensions.logstats] INFO: Crawled 88 pages (at 7 pages/min), scraped 1734 items (at 142 items/min)
2019-06-16 18:48:23 [scrapy.extensions.logstats] INFO: Crawled 96 pages (at 8 pages/min), scraped 1881 items (at 147 items/min)
2019-06-16 18:49:24 [scrapy.extensions.logstats] INFO: Crawled 103 pages (at 7 pages/min), scraped 2032 items (at 151 items/min)
2019-06-16 18:50:23 [scrapy.extensions.logstats] INFO: Crawled 111 pages (at 8 pages/min), scraped 2181 items (at 149 items/min)
2019-06-16 18:51:23 [scrapy.extensions.logstats] INFO: Crawled 118 pages (at 7 pages/min), scraped 2324 items (at 143 items/min)
2019-06-16 18:52:23 [scrapy.extensions.logstats] INFO: Crawled 125 pages (at 7 pages/min), scraped 2469 items (at 145 items/min)
2019-06-16 18:53:23 [scrapy.extensions.logstats] INFO: Crawled 132 pages (at 7 pages/min), scraped 2604 items (at 135 items/min)
2019-06-16 18:54:23 [scrapy.extensions.logstats] INFO: Crawled 139 pages (at 7 pages/min), scraped 2753 items (at 149 items/min)
2019-06-16 18:55:23 [scrapy.extensions.logstats] INFO: Crawled 146 pages (at 7 pages/min), scraped 2897 items (at 144 items/min)
2019-06-16 18:56:23 [scrapy.extensions.logstats] INFO: Crawled 154 pages (at 8 pages/min), scraped 3042 items (at 145 items/min)
2019-06-16 18:57:23 [scrapy.extensions.logstats] INFO: Crawled 161 pages (at 7 pages/min), scraped 3196 items (at 154 items/min)
2019-06-16 18:58:23 [scrapy.extensions.logstats] INFO: Crawled 168 pages (at 7 pages/min), scraped 3337 items (at 141 items/min)
2019-06-16 18:59:23 [scrapy.extensions.logstats] INFO: Crawled 176 pages (at 8 pages/min), scraped 3485 items (at 148 items/min)
2019-06-16 19:00:23 [scrapy.extensions.logstats] INFO: Crawled 183 pages (at 7 pages/min), scraped 3638 items (at 153 items/min)
2019-06-16 19:01:23 [scrapy.extensions.logstats] INFO: Crawled 191 pages (at 8 pages/min), scraped 3792 items (at 154 items/min)
2019-06-16 19:02:23 [scrapy.extensions.logstats] INFO: Crawled 199 pages (at 8 pages/min), scraped 3948 items (at 156 items/min)
2019-06-16 19:03:23 [scrapy.extensions.logstats] INFO: Crawled 206 pages (at 7 pages/min), scraped 4100 items (at 152 items/min)
2019-06-16 19:04:23 [scrapy.extensions.logstats] INFO: Crawled 215 pages (at 9 pages/min), scraped 4267 items (at 167 items/min)
2019-06-16 19:05:23 [scrapy.extensions.logstats] INFO: Crawled 223 pages (at 8 pages/min), scraped 4429 items (at 162 items/min)
2019-06-16 19:06:23 [scrapy.extensions.logstats] INFO: Crawled 230 pages (at 7 pages/min), scraped 4563 items (at 134 items/min)
2019-06-16 19:07:23 [scrapy.extensions.logstats] INFO: Crawled 238 pages (at 8 pages/min), scraped 4725 items (at 162 items/min)
2019-06-16 19:08:23 [scrapy.extensions.logstats] INFO: Crawled 246 pages (at 8 pages/min), scraped 4888 items (at 163 items/min)
2019-06-16 19:09:23 [scrapy.extensions.logstats] INFO: Crawled 250 pages (at 4 pages/min), scraped 4976 items (at 88 items/min)
2019-06-16 19:10:23 [scrapy.extensions.logstats] INFO: Crawled 258 pages (at 8 pages/min), scraped 5134 items (at 158 items/min)
2019-06-16 19:11:23 [scrapy.extensions.logstats] INFO: Crawled 266 pages (at 8 pages/min), scraped 5289 items (at 155 items/min)
2019-06-16 19:12:24 [scrapy.extensions.logstats] INFO: Crawled 274 pages (at 8 pages/min), scraped 5443 items (at 154 items/min)
2019-06-16 19:13:23 [scrapy.extensions.logstats] INFO: Crawled 281 pages (at 7 pages/min), scraped 5595 items (at 152 items/min)
2019-06-16 19:14:23 [scrapy.extensions.logstats] INFO: Crawled 289 pages (at 8 pages/min), scraped 5759 items (at 164 items/min)
2019-06-16 19:15:24 [scrapy.extensions.logstats] INFO: Crawled 297 pages (at 8 pages/min), scraped 5913 items (at 154 items/min)
2019-06-16 19:16:23 [scrapy.extensions.logstats] INFO: Crawled 305 pages (at 8 pages/min), scraped 6068 items (at 155 items/min)
2019-06-16 19:17:24 [scrapy.extensions.logstats] INFO: Crawled 313 pages (at 8 pages/min), scraped 6233 items (at 165 items/min)
2019-06-16 19:18:23 [scrapy.extensions.logstats] INFO: Crawled 321 pages (at 8 pages/min), scraped 6387 items (at 154 items/min)
2019-06-16 19:19:23 [scrapy.extensions.logstats] INFO: Crawled 329 pages (at 8 pages/min), scraped 6541 items (at 154 items/min)
2019-06-16 19:20:24 [scrapy.extensions.logstats] INFO: Crawled 336 pages (at 7 pages/min), scraped 6681 items (at 140 items/min)
2019-06-16 19:21:23 [scrapy.extensions.logstats] INFO: Crawled 343 pages (at 7 pages/min), scraped 6827 items (at 146 items/min)
2019-06-16 19:22:23 [scrapy.extensions.logstats] INFO: Crawled 350 pages (at 7 pages/min), scraped 6971 items (at 144 items/min)
2019-06-16 19:23:23 [scrapy.extensions.logstats] INFO: Crawled 357 pages (at 7 pages/min), scraped 7120 items (at 149 items/min)
2019-06-16 19:24:23 [scrapy.extensions.logstats] INFO: Crawled 365 pages (at 8 pages/min), scraped 7269 items (at 149 items/min)
2019-06-16 19:25:23 [scrapy.extensions.logstats] INFO: Crawled 372 pages (at 7 pages/min), scraped 7405 items (at 136 items/min)
2019-06-16 19:26:23 [scrapy.extensions.logstats] INFO: Crawled 378 pages (at 6 pages/min), scraped 7540 items (at 135 items/min)
2019-06-16 19:27:23 [scrapy.extensions.logstats] INFO: Crawled 385 pages (at 7 pages/min), scraped 7678 items (at 138 items/min)
2019-06-16 19:28:24 [scrapy.extensions.logstats] INFO: Crawled 392 pages (at 7 pages/min), scraped 7818 items (at 140 items/min)
2019-06-16 19:29:23 [scrapy.extensions.logstats] INFO: Crawled 399 pages (at 7 pages/min), scraped 7957 items (at 139 items/min)
2019-06-16 19:30:23 [scrapy.extensions.logstats] INFO: Crawled 406 pages (at 7 pages/min), scraped 8097 items (at 140 items/min)
2019-06-16 19:31:23 [scrapy.extensions.logstats] INFO: Crawled 413 pages (at 7 pages/min), scraped 8236 items (at 139 items/min)
2019-06-16 19:32:23 [scrapy.extensions.logstats] INFO: Crawled 420 pages (at 7 pages/min), scraped 8368 items (at 132 items/min)
2019-06-16 19:33:23 [scrapy.extensions.logstats] INFO: Crawled 426 pages (at 6 pages/min), scraped 8500 items (at 132 items/min)
2019-06-16 19:34:23 [scrapy.extensions.logstats] INFO: Crawled 433 pages (at 7 pages/min), scraped 8633 items (at 133 items/min)
2019-06-16 19:35:23 [scrapy.extensions.logstats] INFO: Crawled 439 pages (at 6 pages/min), scraped 8753 items (at 120 items/min)
2019-06-16 19:36:23 [scrapy.extensions.logstats] INFO: Crawled 446 pages (at 7 pages/min), scraped 8881 items (at 128 items/min)
2019-06-16 19:37:23 [scrapy.extensions.logstats] INFO: Crawled 452 pages (at 6 pages/min), scraped 9007 items (at 126 items/min)
2019-06-16 19:38:23 [scrapy.extensions.logstats] INFO: Crawled 458 pages (at 6 pages/min), scraped 9131 items (at 124 items/min)
2019-06-16 19:39:24 [scrapy.extensions.logstats] INFO: Crawled 464 pages (at 6 pages/min), scraped 9259 items (at 128 items/min)
2019-06-16 19:40:24 [scrapy.extensions.logstats] INFO: Crawled 471 pages (at 7 pages/min), scraped 9397 items (at 138 items/min)
2019-06-16 19:41:23 [scrapy.extensions.logstats] INFO: Crawled 478 pages (at 7 pages/min), scraped 9535 items (at 138 items/min)
2019-06-16 19:42:23 [scrapy.extensions.logstats] INFO: Crawled 485 pages (at 7 pages/min), scraped 9665 items (at 130 items/min)
2019-06-16 19:43:23 [scrapy.extensions.logstats] INFO: Crawled 492 pages (at 7 pages/min), scraped 9804 items (at 139 items/min)
2019-06-16 19:44:23 [scrapy.extensions.logstats] INFO: Crawled 498 pages (at 6 pages/min), scraped 9935 items (at 131 items/min)
2019-06-16 19:45:24 [scrapy.extensions.logstats] INFO: Crawled 506 pages (at 8 pages/min), scraped 10095 items (at 160 items/min)
2019-06-16 19:46:23 [scrapy.extensions.logstats] INFO: Crawled 513 pages (at 7 pages/min), scraped 10226 items (at 131 items/min)
2019-06-16 19:47:23 [scrapy.extensions.logstats] INFO: Crawled 521 pages (at 8 pages/min), scraped 10388 items (at 162 items/min)
2019-06-16 19:48:23 [scrapy.extensions.logstats] INFO: Crawled 529 pages (at 8 pages/min), scraped 10550 items (at 162 items/min)
2019-06-16 19:49:23 [scrapy.extensions.logstats] INFO: Crawled 537 pages (at 8 pages/min), scraped 10712 items (at 162 items/min)
2019-06-16 19:50:23 [scrapy.extensions.logstats] INFO: Crawled 545 pages (at 8 pages/min), scraped 10871 items (at 159 items/min)
2019-06-16 19:51:23 [scrapy.extensions.logstats] INFO: Crawled 553 pages (at 8 pages/min), scraped 11035 items (at 164 items/min)
2019-06-16 19:52:23 [scrapy.extensions.logstats] INFO: Crawled 561 pages (at 8 pages/min), scraped 11194 items (at 159 items/min)
2019-06-16 19:53:23 [scrapy.extensions.logstats] INFO: Crawled 569 pages (at 8 pages/min), scraped 11357 items (at 163 items/min)
2019-06-16 19:54:23 [scrapy.extensions.logstats] INFO: Crawled 577 pages (at 8 pages/min), scraped 11516 items (at 159 items/min)
2019-06-16 19:55:23 [scrapy.extensions.logstats] INFO: Crawled 585 pages (at 8 pages/min), scraped 11673 items (at 157 items/min)
2019-06-16 19:56:23 [scrapy.extensions.logstats] INFO: Crawled 593 pages (at 8 pages/min), scraped 11832 items (at 159 items/min)
2019-06-16 19:57:23 [scrapy.extensions.logstats] INFO: Crawled 601 pages (at 8 pages/min), scraped 11982 items (at 150 items/min)
2019-06-16 19:58:23 [scrapy.extensions.logstats] INFO: Crawled 608 pages (at 7 pages/min), scraped 12137 items (at 155 items/min)
2019-06-16 19:59:23 [scrapy.extensions.logstats] INFO: Crawled 616 pages (at 8 pages/min), scraped 12299 items (at 162 items/min)
2019-06-16 20:00:23 [scrapy.extensions.logstats] INFO: Crawled 624 pages (at 8 pages/min), scraped 12459 items (at 160 items/min)
2019-06-16 20:01:23 [scrapy.extensions.logstats] INFO: Crawled 632 pages (at 8 pages/min), scraped 12617 items (at 158 items/min)
2019-06-16 20:02:23 [scrapy.extensions.logstats] INFO: Crawled 640 pages (at 8 pages/min), scraped 12775 items (at 158 items/min)
2019-06-16 20:03:23 [scrapy.extensions.logstats] INFO: Crawled 648 pages (at 8 pages/min), scraped 12932 items (at 157 items/min)
2019-06-16 20:04:23 [scrapy.extensions.logstats] INFO: Crawled 656 pages (at 8 pages/min), scraped 13093 items (at 161 items/min)
2019-06-16 20:05:23 [scrapy.extensions.logstats] INFO: Crawled 664 pages (at 8 pages/min), scraped 13246 items (at 153 items/min)
2019-06-16 20:06:23 [scrapy.extensions.logstats] INFO: Crawled 671 pages (at 7 pages/min), scraped 13399 items (at 153 items/min)
2019-06-16 20:07:23 [scrapy.extensions.logstats] INFO: Crawled 680 pages (at 9 pages/min), scraped 13567 items (at 168 items/min)
2019-06-16 20:08:23 [scrapy.extensions.logstats] INFO: Crawled 688 pages (at 8 pages/min), scraped 13730 items (at 163 items/min)
2019-06-16 20:09:23 [scrapy.extensions.logstats] INFO: Crawled 696 pages (at 8 pages/min), scraped 13896 items (at 166 items/min)
2019-06-16 20:10:23 [scrapy.extensions.logstats] INFO: Crawled 704 pages (at 8 pages/min), scraped 14060 items (at 164 items/min)
2019-06-16 20:11:23 [scrapy.extensions.logstats] INFO: Crawled 712 pages (at 8 pages/min), scraped 14218 items (at 158 items/min)
2019-06-16 20:12:23 [scrapy.extensions.logstats] INFO: Crawled 720 pages (at 8 pages/min), scraped 14369 items (at 151 items/min)
2019-06-16 20:13:23 [scrapy.extensions.logstats] INFO: Crawled 728 pages (at 8 pages/min), scraped 14524 items (at 155 items/min)
2019-06-16 20:14:23 [scrapy.extensions.logstats] INFO: Crawled 736 pages (at 8 pages/min), scraped 14681 items (at 157 items/min)
2019-06-16 20:15:23 [scrapy.extensions.logstats] INFO: Crawled 743 pages (at 7 pages/min), scraped 14837 items (at 156 items/min)
2019-06-16 20:16:23 [scrapy.extensions.logstats] INFO: Crawled 751 pages (at 8 pages/min), scraped 14992 items (at 155 items/min)
2019-06-16 20:17:23 [scrapy.extensions.logstats] INFO: Crawled 759 pages (at 8 pages/min), scraped 15150 items (at 158 items/min)
2019-06-16 20:18:23 [scrapy.extensions.logstats] INFO: Crawled 767 pages (at 8 pages/min), scraped 15307 items (at 157 items/min)
2019-06-16 20:19:23 [scrapy.extensions.logstats] INFO: Crawled 775 pages (at 8 pages/min), scraped 15464 items (at 157 items/min)
2019-06-16 20:20:23 [scrapy.extensions.logstats] INFO: Crawled 782 pages (at 7 pages/min), scraped 15618 items (at 154 items/min)
2019-06-16 20:21:23 [scrapy.extensions.logstats] INFO: Crawled 790 pages (at 8 pages/min), scraped 15776 items (at 158 items/min)
2019-06-16 20:22:23 [scrapy.extensions.logstats] INFO: Crawled 798 pages (at 8 pages/min), scraped 15934 items (at 158 items/min)
2019-06-16 20:23:23 [scrapy.extensions.logstats] INFO: Crawled 806 pages (at 8 pages/min), scraped 16093 items (at 159 items/min)
2019-06-16 20:24:23 [scrapy.extensions.logstats] INFO: Crawled 814 pages (at 8 pages/min), scraped 16250 items (at 157 items/min)
2019-06-16 20:25:23 [scrapy.extensions.logstats] INFO: Crawled 821 pages (at 7 pages/min), scraped 16394 items (at 144 items/min)
2019-06-16 20:26:23 [scrapy.extensions.logstats] INFO: Crawled 828 pages (at 7 pages/min), scraped 16540 items (at 146 items/min)
2019-06-16 20:27:23 [scrapy.extensions.logstats] INFO: Crawled 835 pages (at 7 pages/min), scraped 16675 items (at 135 items/min)
2019-06-16 20:28:23 [scrapy.extensions.logstats] INFO: Crawled 842 pages (at 7 pages/min), scraped 16810 items (at 135 items/min)
2019-06-16 20:29:23 [scrapy.extensions.logstats] INFO: Crawled 849 pages (at 7 pages/min), scraped 16948 items (at 138 items/min)
2019-06-16 20:30:23 [scrapy.extensions.logstats] INFO: Crawled 856 pages (at 7 pages/min), scraped 17093 items (at 145 items/min)
2019-06-16 20:31:23 [scrapy.extensions.logstats] INFO: Crawled 863 pages (at 7 pages/min), scraped 17227 items (at 134 items/min)
2019-06-16 20:32:23 [scrapy.extensions.logstats] INFO: Crawled 870 pages (at 7 pages/min), scraped 17380 items (at 153 items/min)
2019-06-16 20:33:23 [scrapy.extensions.logstats] INFO: Crawled 877 pages (at 7 pages/min), scraped 17519 items (at 139 items/min)
2019-06-16 20:34:24 [scrapy.extensions.logstats] INFO: Crawled 885 pages (at 8 pages/min), scraped 17664 items (at 145 items/min)
2019-06-16 20:35:24 [scrapy.extensions.logstats] INFO: Crawled 891 pages (at 6 pages/min), scraped 17796 items (at 132 items/min)
2019-06-16 20:36:23 [scrapy.extensions.logstats] INFO: Crawled 899 pages (at 8 pages/min), scraped 17941 items (at 145 items/min)
2019-06-16 20:37:23 [scrapy.extensions.logstats] INFO: Crawled 906 pages (at 7 pages/min), scraped 18096 items (at 155 items/min)
2019-06-16 20:38:23 [scrapy.extensions.logstats] INFO: Crawled 914 pages (at 8 pages/min), scraped 18257 items (at 161 items/min)
2019-06-16 20:39:23 [scrapy.extensions.logstats] INFO: Crawled 922 pages (at 8 pages/min), scraped 18409 items (at 152 items/min)
2019-06-16 20:40:23 [scrapy.extensions.logstats] INFO: Crawled 930 pages (at 8 pages/min), scraped 18561 items (at 152 items/min)
2019-06-16 20:41:23 [scrapy.extensions.logstats] INFO: Crawled 937 pages (at 7 pages/min), scraped 18713 items (at 152 items/min)
2019-06-16 20:42:23 [scrapy.extensions.logstats] INFO: Crawled 944 pages (at 7 pages/min), scraped 18859 items (at 146 items/min)
2019-06-16 20:43:23 [scrapy.extensions.logstats] INFO: Crawled 951 pages (at 7 pages/min), scraped 18991 items (at 132 items/min)
2019-06-16 20:44:23 [scrapy.extensions.logstats] INFO: Crawled 958 pages (at 7 pages/min), scraped 19138 items (at 147 items/min)
2019-06-16 20:45:23 [scrapy.extensions.logstats] INFO: Crawled 965 pages (at 7 pages/min), scraped 19275 items (at 137 items/min)
2019-06-16 20:46:23 [scrapy.extensions.logstats] INFO: Crawled 972 pages (at 7 pages/min), scraped 19418 items (at 143 items/min)
2019-06-16 20:47:23 [scrapy.extensions.logstats] INFO: Crawled 980 pages (at 8 pages/min), scraped 19574 items (at 156 items/min)
2019-06-16 20:48:23 [scrapy.extensions.logstats] INFO: Crawled 988 pages (at 8 pages/min), scraped 19728 items (at 154 items/min)
2019-06-16 20:49:23 [scrapy.extensions.logstats] INFO: Crawled 996 pages (at 8 pages/min), scraped 19884 items (at 156 items/min)
2019-06-16 20:50:23 [scrapy.extensions.logstats] INFO: Crawled 1004 pages (at 8 pages/min), scraped 20050 items (at 166 items/min)
2019-06-16 20:51:23 [scrapy.extensions.logstats] INFO: Crawled 1012 pages (at 8 pages/min), scraped 20208 items (at 158 items/min)
2019-06-16 20:52:23 [scrapy.extensions.logstats] INFO: Crawled 1019 pages (at 7 pages/min), scraped 20355 items (at 147 items/min)
2019-06-16 20:53:23 [scrapy.extensions.logstats] INFO: Crawled 1027 pages (at 8 pages/min), scraped 20513 items (at 158 items/min)
2019-06-16 20:54:23 [scrapy.extensions.logstats] INFO: Crawled 1035 pages (at 8 pages/min), scraped 20672 items (at 159 items/min)
2019-06-16 20:55:23 [scrapy.extensions.logstats] INFO: Crawled 1042 pages (at 7 pages/min), scraped 20816 items (at 144 items/min)
2019-06-16 20:56:23 [scrapy.extensions.logstats] INFO: Crawled 1050 pages (at 8 pages/min), scraped 20975 items (at 159 items/min)
2019-06-16 20:57:23 [scrapy.extensions.logstats] INFO: Crawled 1057 pages (at 7 pages/min), scraped 21108 items (at 133 items/min)
2019-06-16 20:58:23 [scrapy.extensions.logstats] INFO: Crawled 1064 pages (at 7 pages/min), scraped 21256 items (at 148 items/min)
2019-06-16 20:59:23 [scrapy.extensions.logstats] INFO: Crawled 1072 pages (at 8 pages/min), scraped 21407 items (at 151 items/min)
2019-06-16 21:00:23 [scrapy.extensions.logstats] INFO: Crawled 1080 pages (at 8 pages/min), scraped 21565 items (at 158 items/min)
2019-06-16 21:01:23 [scrapy.extensions.logstats] INFO: Crawled 1087 pages (at 7 pages/min), scraped 21704 items (at 139 items/min)
2019-06-16 21:02:23 [scrapy.extensions.logstats] INFO: Crawled 1095 pages (at 8 pages/min), scraped 21862 items (at 158 items/min)
2019-06-16 21:03:23 [scrapy.extensions.logstats] INFO: Crawled 1103 pages (at 8 pages/min), scraped 22021 items (at 159 items/min)
2019-06-16 21:04:23 [scrapy.extensions.logstats] INFO: Crawled 1110 pages (at 7 pages/min), scraped 22180 items (at 159 items/min)
2019-06-16 21:05:23 [scrapy.extensions.logstats] INFO: Crawled 1118 pages (at 8 pages/min), scraped 22336 items (at 156 items/min)
2019-06-16 21:06:23 [scrapy.extensions.logstats] INFO: Crawled 1126 pages (at 8 pages/min), scraped 22494 items (at 158 items/min)
2019-06-16 22:11:08 [scrapy.core.scraper] ERROR: Error processing {'imgname': '其实我喜欢 吃东西，什么都爱吃',
 'imgurl': 'https://ww3.sinaimg.cn/bmiddle/0060lm7Tgy1fcpu4wgl0lj30dw0op0uv.jpg'}
Traceback (most recent call last):
  File "G:\Flask\lib\site-packages\urllib3\contrib\pyopenssl.py", line 444, in wrap_socket
    cnx.do_handshake()
  File "C:\Users\ltf\AppData\Local\Programs\Python\Python36\lib\site-packages\OpenSSL\SSL.py", line 1915, in do_handshake
    self._raise_ssl_error(self._ssl, result)
  File "C:\Users\ltf\AppData\Local\Programs\Python\Python36\lib\site-packages\OpenSSL\SSL.py", line 1639, in _raise_ssl_error
    raise SysCallError(errno, errorcode.get(errno))
OpenSSL.SSL.SysCallError: (10060, 'WSAETIMEDOUT')

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "G:\Flask\lib\site-packages\urllib3\connectionpool.py", line 600, in urlopen
    chunked=chunked)
  File "G:\Flask\lib\site-packages\urllib3\connectionpool.py", line 343, in _make_request
    self._validate_conn(conn)
  File "G:\Flask\lib\site-packages\urllib3\connectionpool.py", line 849, in _validate_conn
    conn.connect()
  File "G:\Flask\lib\site-packages\urllib3\connection.py", line 356, in connect
    ssl_context=context)
  File "G:\Flask\lib\site-packages\urllib3\util\ssl_.py", line 359, in ssl_wrap_socket
    return context.wrap_socket(sock, server_hostname=server_hostname)
  File "G:\Flask\lib\site-packages\urllib3\contrib\pyopenssl.py", line 450, in wrap_socket
    raise ssl.SSLError('bad handshake: %r' % e)
ssl.SSLError: ("bad handshake: SysCallError(10060, 'WSAETIMEDOUT')",)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "G:\Flask\lib\site-packages\requests\adapters.py", line 445, in send
    timeout=timeout
  File "G:\Flask\lib\site-packages\urllib3\connectionpool.py", line 638, in urlopen
    _stacktrace=sys.exc_info()[2])
  File "G:\Flask\lib\site-packages\urllib3\util\retry.py", line 398, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='ww3.sinaimg.cn', port=443): Max retries exceeded with url: /bmiddle/0060lm7Tgy1fcpu4wgl0lj30dw0op0uv.jpg (Caused by SSLError(SSLError("bad handshake: SysCallError(10060, 'WSAETIMEDOUT')",),))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\ltf\AppData\Local\Programs\Python\Python36\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "G:\pythonAI\爬虫大全\dbmeinv\dbmeinv\iopipeline.py", line 16, in process_item
    r = requests.get(item['imgurl'], headers=headers)
  File "G:\Flask\lib\site-packages\requests\api.py", line 72, in get
    return request('get', url, params=params, **kwargs)
  File "G:\Flask\lib\site-packages\requests\api.py", line 58, in request
    return session.request(method=method, url=url, **kwargs)
  File "G:\Flask\lib\site-packages\requests\sessions.py", line 512, in request
    resp = self.send(prep, **send_kwargs)
  File "G:\Flask\lib\site-packages\requests\sessions.py", line 622, in send
    r = adapter.send(request, **kwargs)
  File "G:\Flask\lib\site-packages\requests\adapters.py", line 511, in send
    raise SSLError(e, request=request)
requests.exceptions.SSLError: HTTPSConnectionPool(host='ww3.sinaimg.cn', port=443): Max retries exceeded with url: /bmiddle/0060lm7Tgy1fcpu4wgl0lj30dw0op0uv.jpg (Caused by SSLError(SSLError("bad handshake: SysCallError(10060, 'WSAETIMEDOUT')",),))
2019-06-16 22:11:08 [scrapy.extensions.logstats] INFO: Crawled 1133 pages (at 7 pages/min), scraped 22634 items (at 140 items/min)
